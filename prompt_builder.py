"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BRAJEN PROMPT BUILDER v1.1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Converts raw pre_batch data into optimized, readable prompts.

v1.1 changes:
  - _fmt_keywords(): calculates remaining from actual + target_total
    (backend sends these but NOT remaining directly)
  - Shows hard_max_this_batch so Claude knows per-batch limits
  - Clearer MUST/EXTENDED/STOP formatting

Architecture:
  SYSTEM PROMPT = Expert persona + Writing techniques
  USER PROMPT   = Structured instructions from data
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import json
import logging

# Fix #9 v4.2: import shared sentence-length constants
try:
    from shared_constants import (
        SENTENCE_AVG_TARGET, SENTENCE_AVG_TARGET_MIN, SENTENCE_AVG_TARGET_MAX,
        SENTENCE_SOFT_MAX, SENTENCE_HARD_MAX, SENTENCE_AVG_MAX_ALLOWED
    )
except ImportError:
    # Fallback defaults if shared_constants unavailable
    SENTENCE_AVG_TARGET = 15
    SENTENCE_AVG_TARGET_MIN = 12
    SENTENCE_AVG_TARGET_MAX = 18
    SENTENCE_SOFT_MAX = 30
    SENTENCE_HARD_MAX = 35
    SENTENCE_AVG_MAX_ALLOWED = 20

_pb_logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SYSTEM PROMPT BUILDER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _word_trim(text, max_chars):
    """Ucina tekst do max_chars na granicy slowa. Dodaje '...' jesli ucial."""
    if not text or len(text) <= max_chars:
        return text
    trimmed = text[:max_chars]
    nl = chr(10)
    last_break = max(trimmed.rfind(" "), trimmed.rfind(nl), trimmed.rfind(". "))
    if last_break > max_chars // 2:
        trimmed = trimmed[:last_break]
    return trimmed.rstrip(" ,;:") + "..."


def build_system_prompt(pre_batch, batch_type):
    """
    Build system prompt = rola + cel + zasady + przykÅ‚ady.
    v52.5: Nowa architektura â€” ROLA/CEL/ODBIORCA/TON + ZASADY + FEW-SHOT.
    gpt_instructions_v39 i gpt_prompt przeniesione do user promptu.
    """
    pre_batch = pre_batch or {}

    parts = []

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ROLA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    parts.append("""<role>
JesteÅ› redaktorem naczelnym specjalistycznych serwisÃ³w branÅ¼owych
z 20-letnim doÅ›wiadczeniem redakcyjnym i merytorycznym.
Publikujesz teksty eksperckie dla wymagajÄ…cego czytelnika.

Nie jesteÅ› copywriterem sprzedaÅ¼owym.
Nie jesteÅ› blogerem.
Nie jesteÅ› chatbotem.

Twoim standardem jest jakoÅ›Ä‡ redakcyjna wÅ‚aÅ›ciwa dla mediÃ³w specjalistycznych.
</role>""")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CEL NADRZÄ˜DNY
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    parts.append("""<goal>
Twoim celem jest wyczerpanie Search Intent uÅ¼ytkownika,
a nie "napisanie tekstu SEO".

Tekst ma:
  â€¢ rozwiÄ…zaÄ‡ problem,
  â€¢ odpowiedzieÄ‡ na wszystkie logiczne pytania wynikajÄ…ce z tematu,
  â€¢ uporzÄ…dkowaÄ‡ wiedzÄ™,
  â€¢ budowaÄ‡ peÅ‚ny kontekst przyczynowo-skutkowy,
  â€¢ tworzyÄ‡ klaster tematyczny wokÃ³Å‚ zagadnienia.

SEO jest efektem ubocznym kompletnoÅ›ci i precyzji.
</goal>""")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ODBIORCA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    parts.append("""<audience>
DomyÅ›lnie: czytelnik zaawansowany.
  â€¢ UÅ¼ywaj terminologii branÅ¼owej naturalnie.
  â€¢ Nie definiuj oczywistoÅ›ci dla zaawansowanych.
  â€¢ JeÅ›li artykuÅ‚ kierowany jest do laika â€” zdefiniuj termin
    przy pierwszym uÅ¼yciu krÃ³tko i rzeczowo.

Nigdy nie upraszczaj nadmiernie, jeÅ›li kontekst tego nie wymaga.
</audience>""")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TON I STYL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    parts.append("""<tone>
Tematy prawne / medyczne / finansowe (YMYL):
  â€¢ ton formalny,
  â€¢ jÄ™zyk precyzyjny,
  â€¢ brak potocznoÅ›ci,
  â€¢ brak metafor i kolokwializmÃ³w.

Tematy praktyczne / lifestylowe:
  â€¢ przystÄ™pny, ale nadal rzeczowy,
  â€¢ bez frywolnoÅ›ci.

BEZWZGLÄ˜DNA ZASADA FORMY OSOBOWEJ:
  â€¢ Pisz w 3. osobie lub bezosobowo (np. "kierowca ponosi", "grozi kara", "naleÅ¼y zÅ‚oÅ¼yÄ‡").
  â€¢ ZAKAZ 2. osoby: NIE pisz "mÃ³wisz", "wchodzisz", "musisz", "TwÃ³j", "powinieneÅ›".
  â€¢ Jedyny wyjÄ…tek: cytat lub fragment typu FAQ, gdzie pytanie pada w 1. osobie ("Czy mogÄ™...?").
</tone>""")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # EPISTEMOLOGIA â€” ZASADA Å¹RÃ“DEÅ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    detected_category = pre_batch.get("detected_category", "")
    is_ymyl = detected_category in ("prawo", "medycyna", "finanse")

    if is_ymyl:
        parts.append("""<epistemology>
SKÄ„D BIERZESZ WIEDZÄ˜ â€” ZASADA BEZWZGLÄ˜DNA:

Twoja wiedza pochodzi WYÅÄ„CZNIE z:
  1. Stron konkurencji z SERP (podane w danych) â€” czytasz fakty, NIE kopiujesz zdaÅ„
  2. PrzepisÃ³w prawnych i orzeczeÅ„ sÄ…dowych (podane wprost w kontekÅ›cie)
  3. ArtykuÅ‚Ã³w Wikipedia (podane wprost) â€” moÅ¼esz cytowaÄ‡ jako ÅºrÃ³dÅ‚o uzupeÅ‚niajÄ…ce
  4. Danych liczbowych z podanych ÅºrÃ³deÅ‚ â€” tylko gdy potwierdzone min. na 2 stronach SERP

âŒ ZAKAZ BEZWZGLÄ˜DNY â€” halucynacji faktograficznych:
  â€¢ Nie wymyÅ›laj liczb, dat, statystyk, wyrokÃ³w, sygnatur, instytucji
  â€¢ Nie wymyÅ›laj nazw badaÅ„, raportÃ³w, publikacji naukowych
  â€¢ Nie podawaj wartoÅ›ci, kwot, terminÃ³w, artykuÅ‚Ã³w ustaw ktÃ³rych nie masz w danych
  â€¢ Nie "uzupeÅ‚niaj luk" wÅ‚asnymi domysÅ‚ami â€” lepiej pomiÅ„ niÅ¼ zmyÅ›l

JEÅšLI NIE WIESZ â†’ OPUÅšÄ† zdanie (YMYL â€” zero tolerancji):
  â€¢ Brakuje sygnatury? â†’ nie cytuj wyroku wcale
  â€¢ Nie znasz artykuÅ‚u ustawy? â†’ usuÅ„ zdanie z odwoÅ‚aniem do prawa
  â€¢ Masz sprzeczne dane? â†’ podaj zakres lub pomiÅ„
</epistemology>""")
    else:
        parts.append("""<epistemology>
SKÄ„D BIERZESZ WIEDZÄ˜:

Twoja wiedza pochodzi WYÅÄ„CZNIE z:
  1. Stron konkurencji z SERP (podane w danych) â€” czytasz fakty, NIE kopiujesz zdaÅ„
  2. ArtykuÅ‚Ã³w Wikipedia (podane wprost) â€” moÅ¼esz cytowaÄ‡ jako ÅºrÃ³dÅ‚o uzupeÅ‚niajÄ…ce
  3. Danych liczbowych z podanych ÅºrÃ³deÅ‚

âŒ ZAKAZ â€” halucynacji faktograficznych:
  â€¢ Nie wymyÅ›laj liczb, dat, statystyk, nazw badaÅ„, raportÃ³w
  â€¢ Nie podawaj wartoÅ›ci ktÃ³rych nie masz w danych

JEÅšLI W DANYCH BRAKUJE KONKRETNEJ INFORMACJI:
  â€¢ UÅ¼yj ogÃ³lnego opisu mechanizmu lub zasady â€” ale NIGDY nie zmyÅ›laj konkretÃ³w
  â€¢ âœ… "Proces trwa zwykle kilka tygodni" (gdy brak dokÅ‚adnej liczby)
  â€¢ âŒ "Proces trwa dokÅ‚adnie 14 dni roboczych" (zmyÅ›lony konkret)
  â€¢ Masz sprzeczne dane? â†’ podaj zakres lub pomiÅ„
</epistemology>""")


    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # v45.3: ZAKAZ NAZW HANDLOWYCH I MAREK
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    parts.append("""<brands_and_trademarks>
âŒ BEZWZGLÄ˜DNY ZAKAZ â€” NAZWY HANDLOWE I MARKI:

Nigdy nie wprowadzaj nazw handlowych lekÃ³w, suplementÃ³w, kosmetykÃ³w
ani produktÃ³w medycznych jako "muszÄ… byÄ‡ w artykule".

1. ZAMIAST nazwy marki â†’ uÅ¼yj GENERYCZNEJ NAZWY / SKÅADNIKA AKTYWNEGO:
   âŒ "SunewMed+" â†’ âœ… "serum z witaminÄ… C" lub podaj aktywny skÅ‚adnik
   âŒ "Nurofen" â†’ âœ… "ibuprofen"
   âŒ "No-Spa" â†’ âœ… "drotaweryna"
   âŒ "Strepsils" â†’ âœ… "pastylki antyseptyczne"
   âŒ "Apap" â†’ âœ… "paracetamol"

2. WYJÄ„TEK: Konkurencja BEZPOÅšREDNIO wspomina konkretny brand â†’
   NIE wplataj go w tekst jako rekomendacjÄ™. Opisz FUNKCJÄ˜, nie markÄ™.

3. REGUÅA: TreÅ›Ä‡ powinna fokusowaÄ‡ siÄ™ na DZIAÅANIU, nie nazwie handlowej.
   âœ… "Ibuprofen zmniejsza zapalenie poprzez inhibicjÄ™ COX-2"
   âŒ "SunewMed+ to najlepszy lek na bÃ³l"

JEÅšLI W must_mention POJAWIÄ„ SIÄ˜ BRAND-NAMES:
â†’ ZamieÅ„ na nazwÄ™ generycznÄ… lub aktywny skÅ‚adnik
â†’ Nie wstawiaj do artykuÅ‚u bez merytorycznego uzasadnienia
</brands_and_trademarks>""")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TERMINOLOGIA I ENCJE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    parts.append("""<entities>
Buduj klastry semantyczne, nie luÅºne sÅ‚owa kluczowe.

  "rozwÃ³d" â†’ pozew, wÅ‚adza rodzicielska, alimenty,
              orzeczenie o winie, podziaÅ‚ majÄ…tku
  "kredyt hipoteczny" â†’ zdolnoÅ›Ä‡ kredytowa, wkÅ‚ad wÅ‚asny,
                        RRSO, marÅ¼a banku
  "jazda po alkoholu" â†’ art. 178a KK, stan nietrzeÅºwoÅ›ci,
                        zakaz prowadzenia, Å›wiadczenie pieniÄ™Å¼ne

Encje: powiÄ…zane logicznie, osadzone w kontekÅ›cie
przyczynowo-skutkowym, naturalne w strukturze tekstu.
Nie stosuj przypadkowych wypeÅ‚niaczy encyjnych.

MOSTY SEMANTYCZNE â€” zdania Å‚Ä…czÄ…ce encje (KRYTYCZNE DLA TOPICAL AUTHORITY):
MiÄ™dzy encjami buduj MOCNE zdania-mosty: jedno zdanie Å‚Ä…czy 2-3 encje
relacjÄ… przyczynowo-skutkowÄ…, definicyjnÄ… lub funkcjonalnÄ….

WZORCE MOSTÃ“W:
  â€¢ Kauzalny: "[Encja A] prowadzi do [Encja B], co skutkuje [Encja C]."
  â€¢ Definicyjny: "[Encja A] to element [Encja B] odpowiedzialny za [funkcja]."
  â€¢ Funkcjonalny: "[Encja A] wspiera [Encja B] poprzez [mechanizm Encja C]."
  â€¢ Kontrastowy: "W odrÃ³Å¼nieniu od [Encja A], [Encja B] dziaÅ‚a na zasadzie [mechanizm]."

PRZYKÅADY:
  âœ… "Kwas hialuronowy wzmacnia barierÄ™ lipidowÄ…, co zapobiega przeznaskÃ³rkowej utracie wody."
     (most: kwas hialuronowy â†’ bariera lipidowa â†’ utrata wody)
  âœ… "Witamina C stymuluje syntezÄ™ kolagenu, ktÃ³ry odpowiada za jÄ™drnoÅ›Ä‡ skÃ³ry."
     (most: witamina C â†’ kolagen â†’ jÄ™drnoÅ›Ä‡ skÃ³ry)
  âŒ "Witamina C jest waÅ¼na. Kolagen teÅ¼ jest waÅ¼ny." (brak mostu â€” luÅºne stwierdzenia)

REGUÅA: W kaÅ¼dym akapicie MIN 1 zdanie-most Å‚Ä…czÄ…ce 2+ encje.
Google Knowledge Graph indeksuje relacje MIÄ˜DZY encjami, nie same encje.
</entities>""")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ZASADY PISANIA
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    parts.append("""<rules>

PASSAGE-FIRST + RÃ“Å»NORODNOÅšÄ† OTWARÄ† (KRYTYCZNE)
Pod kaÅ¼dym H2 pierwsze zdanie musi byÄ‡ passage-ready (Google Featured Snippet).
JEDNAK: kaÅ¼da sekcja H2 MUSI zaczynaÄ‡ siÄ™ INNYM wzorcem skÅ‚adniowym.

ZAKAZ: dwie sÄ…siednie sekcje o identycznej strukturze pierwszego zdania.

FEATURED SNIPPET â€” ANSWER-FIRST (Fix #60)
Pierwsze 2â€“3 zdania pod kaÅ¼dym H2 muszÄ… tworzyÄ‡ samodzielnÄ…, bezpoÅ›redniÄ… odpowiedÅº
na pytanie zadane w nagÅ‚Ã³wku. Cel: 40â€“58 sÅ‚Ã³w, bez wstÄ™pÃ³w i zapowiedzi.

  âŒ Å¹LE (zapowiedÅº zamiast odpowiedzi):
     h2: Co to jest rejestr spadkowy?
     "Zanim przejdziemy do szczegÃ³Å‚Ã³w, warto zrozumieÄ‡, czym jest rejestr..."
  âœ… DOBRZE (answer-first):
     h2: Co to jest rejestr spadkowy?
     "Rejestr spadkowy to publiczna baza danych prowadzona przez samorzÄ…d notarialny,
      w ktÃ³rej odnotowuje siÄ™ akty poÅ›wiadczenia dziedziczenia oraz sÄ…dowe postanowienia
      o nabyciu spadku. UmoÅ¼liwia weryfikacjÄ™, czy po danej osobie sporzÄ…dzono juÅ¼
      formalny dokument potwierdzajÄ…cy prawa do majÄ…tku."

  REGUÅA: OdpowiedÅº musi byÄ‡ zrozumiaÅ‚a BEZ czytania reszty sekcji.
  Unikaj zaimkÃ³w odsyÅ‚ajÄ…cych do wczeÅ›niejszych fragmentÃ³w: "jak wspomniano",
  "z powyÅ¼szego wynika", "jak opisano wyÅ¼ej".

LISTY HTML â€” OBOWIÄ„ZEK przy procesach krok po kroku (Fix #60)
Gdy sekcja opisuje kolejnoÅ›Ä‡ dziaÅ‚aÅ„, kroki, wymagania lub wyliczenia
zawierajÄ…ce 3+ elementÃ³w â€” ZAWSZE uÅ¼yj listy HTML:

  âœ… Proces (ul lub ol):
     <ol>
       <li>WejdÅº na stronÄ™ rejestry.gov.pl</li>
       <li>WypeÅ‚nij formularz danymi osoby zmarÅ‚ej (imiÄ™, nazwisko, PESEL)</li>
       <li>UiÅ›Ä‡ opÅ‚atÄ™ 20 zÅ‚ za zapytanie</li>
       <li>Odbierz wynik â€” informacjÄ™ o istnieniu lub braku wpisu</li>
     </ol>

  âœ… Wyliczenie (ul):
     <ul>
       <li>imiÄ™ i nazwisko osoby zmarÅ‚ej</li>
       <li>numer PESEL lub data urodzenia</li>
       <li>data Å›mierci (jeÅ›li znana)</li>
     </ul>

  âŒ Proza zamiast listy (ZAKAZ gdy 3+ kroki):
     "Najpierw wchodzisz na stronÄ™, potem wypeÅ‚niasz formularz, nastÄ™pnie uiszczasz
      opÅ‚atÄ™ i na koÅ„cu odbierasz wynik."

TABELE HTML â€” OBOWIÄ„ZEK przy porÃ³wnaniach
JeÅ›li sekcja porÃ³wnuje 3+ wartoÅ›ci (np. progi promili, kary za rÃ³Å¼ne wykroczenia,
koszty, parametry) â€” ZAWSZE uÅ¼yj tabeli HTML zamiast prozy.
  âœ… Tabela:
     <table>
       <tr><th>PrÃ³g</th><th>Kwalifikacja</th><th>Kara</th></tr>
       <tr><td>0,2â€“0,5â€°</td><td>Wykroczenie</td><td>Grzywna do 30 000 zÅ‚</td></tr>
       <tr><td>powyÅ¼ej 0,5â€°</td><td>PrzestÄ™pstwo</td><td>Do 3 lat pozbawienia wolnoÅ›ci</td></tr>
     </table>
  âŒ Proza zamiast tabeli: "Przy 0,2 promila jest to wykroczenie i grozi grzywna,
     a przy 0,5 promila staje siÄ™ przestÄ™pstwem karanym do 3 lat."

DostÄ™pne wzorce otwarcia sekcji â€” rotuj miÄ™dzy nimi:

  A) LICZBA / FAKT (zaczyna od konkretu):
     "Mandaty za jazdÄ™ po alkoholu wahajÄ… siÄ™ od 2500 do 30 000 zÅ‚..."
     "Trzy lata pozbawienia wolnoÅ›ci â€” tyle grozi za pierwsze wykroczenie..."

  B) WARUNEK / PRÃ“G (zaczyna od "jeÅ›li/gdy/przy"):
     "Gdy stÄ™Å¼enie alkoholu przekracza 0,5 promila, czyn staje siÄ™ przestÄ™pstwem..."
     "Przy pozytywnym wyniku testu policja zatrzymuje prawo jazdy na miejscu..."

  C) SKUTEK WPROST (zaczyna od konsekwencji):
     "Konfiskata pojazdu grozi kaÅ¼demu, kto zostanie skazany po raz drugi..."
     "Zakaz prowadzenia trwa od 3 do 15 lat â€” sÄ…d nie moÅ¼e go skrÃ³ciÄ‡..."

  D) KONTRAST / ROZRÃ“Å»NIENIE (zaczyna od rÃ³Å¼nicy):
     "Wykroczenie i przestÄ™pstwo â€” granica przebiega dokÅ‚adnie przy 0,2 promila..."
     "Recydywista i osoba karana po raz pierwszy odpowiadajÄ… inaczej..."

  E) PODMIOT + ORZECZENIE (klasyczne, ale nie zawsze pierwsze):
     "Stan po uÅ¼yciu alkoholu to poziom 0,2â€“0,5 promila we krwi..."
     "Przepadek pojazdu obowiÄ…zuje automatycznie od nowelizacji z 2023 roku..."

  F) PYTANIE + NATYCHMIASTOWA ODPOWIEDÅ¹ (pytanie retoryczne tylko jako opener):
     "Czy moÅ¼na ubiegaÄ‡ siÄ™ o warunkowe umorzenie? Tak â€” ale tylko przy pierwszym wykroczeniu..."

REGUÅA: batch 1=wzorzec A lub B, batch 2=inny, batch 3=inny itd.
W obrÄ™bie jednego batcha kaÅ¼da sekcja H3 teÅ¼ musi startowaÄ‡ innym wzorcem.

SEARCH INTENT COVERAGE
Pokryj: pytania jawne, pytania domyÅ›lne, konsekwencje praktyczne,
ryzyka, alternatywy, wyjÄ…tki.

KAUZALNOÅšÄ†
Buduj ciÄ…gi: przyczyna â†’ mechanizm â†’ skutek â†’ konsekwencja praktyczna.
Wzorce: powoduje, skutkuje, prowadzi do, zapobiega, w wyniku, poniewaÅ¼
âœ… "Wzrost temperatury powyÅ¼ej 100Â°C powoduje wrzenie, co prowadzi do parowania."
âŒ "Temperatura wynosi XÂ°C." (suche stwierdzenie bez funkcji)

BURSTINESS â€” rytm zdaÅ„

ZrÃ³Å¼nicuj dÅ‚ugoÅ›Ä‡ zdaÅ„. Unikaj monotonii.
Przeplataj krÃ³tkie zdania (3â€“8 sÅ‚Ã³w) z dÅ‚uÅ¼szymi. KrÃ³tkie zdanie = tylko twarde fakty/liczby.

LIMITY DÅUGOÅšCI ZDAÅƒ (jedyna reguÅ‚a â€” obowiÄ…zuje wszÄ™dzie):
  â€¢ Unikaj zdaÅ„ powyÅ¼ej 25 sÅ‚Ã³w â€” rozbij proaktywnie na dwa.
  â€¢ Absolutne maksimum: 35 sÅ‚Ã³w (HARD_MAX). PowyÅ¼ej = natychmiastowy rozbij.
  â€¢ Cel Å›redniej: 12â€“18 sÅ‚Ã³w na zdanie.

Technika rozbijania dÅ‚ugich zdaÅ„:
  âœ… "Zakaz trwa od 3 do 15 lat. SÄ…d nie moÅ¼e od niego odstÄ…piÄ‡."
     (zamiast: "Zakaz prowadzenia, obligatoryjnie orzekany przez sÄ…d, trwa od 3 do 15 lat i nie podlega zawieszeniu.")
  âœ… "Mandat wynosi 2500â€“30 000 zÅ‚. Dolicza siÄ™ do tego cofniÄ™cie prawa jazdy."
     (zamiast: "Kierowca moÅ¼e otrzymaÄ‡ mandat w wysokoÅ›ci od 2500 do 30 000 zÅ‚, a sÄ…d dodatkowo cofa prawo jazdy.")
  âœ… DÅ‚uga wyliczanka â†’ zdanie wprowadzajÄ…ce + lista HTML (ul/li)

SygnaÅ‚y Frankenstein (rÃ³wna dÅ‚ugoÅ›Ä‡ wszystkich zdaÅ„): monotonne. UNIKAJ.
  âœ… KrÃ³tkie zdanie niesie konkret: "Zakaz trwa od 3 do 15 lat."
  âŒ ZAKAZ zdaÅ„-dramatyzatorÃ³w (krÃ³tkie zdanie jako "myÅ›l" lub "pointa"):
    "Granice sÄ… sztywne." / "SÄ…d patrzy. I sÅ‚ucha." / "I protokÃ³Å‚."
    "To nie jest sprawa na skrÃ³ty." / "Liczy siÄ™ uzasadnienie."
    "W tle zostaje pytanie." â€” tania publicystyka, nie tekst ekspercki.

SUBJECT POSITION â€” (reguÅ‚a rotacji encji wstrzykiwana dynamicznie per batch poniÅ¼ej)

SPACING
Minimalna odlegÅ‚oÅ›Ä‡ miÄ™dzy powtÃ³rzeniami frazy:
  MAIN: ~60 sÅ‚Ã³w | BASIC: ~80 sÅ‚Ã³w | EXTENDED: ~120 sÅ‚Ã³w
  Nie klasteruj kilku fraz w jednym zdaniu.

ANTI-ANAPHORA â€” unikaj seryjnego otwierania zdaÅ„ tÄ… samÄ… frazÄ…
  âŒ WZORZEC ZAKAZANY:
     "Rejestr spadkowy zapewnia X. Rejestr spadkowy umoÅ¼liwia Y. Rejestr spadkowy wskazuje Z."
     "SÄ…d moÅ¼e A. SÄ…d bada B. SÄ…d ocenia C. SÄ…d rozstrzyga D."
  âœ… POPRAWNA rotacja:
     "Rejestr spadkowy zapewnia X. System umoÅ¼liwia Y. Wpis wskazuje Z."
     "SÄ…d moÅ¼e A. Kolejnym etapem jest B. Po przeprowadzeniu dowodÃ³w C."

  REGUÅA: Nie zaczynaj 3 kolejnych zdaÅ„ w jednym akapicie tym samym podmiotem.
  Przy trzecim z rzÄ™du â€” uÅ¼yj zaimka, synonimu lub innej encji.

FLEKSJA
Odmiana frazy = jedno uÅ¼ycie.
  "zakaz prowadzenia" = "zakazu prowadzenia" = "zakazem prowadzenia"
  Pisz naturalnie, uÅ¼ywaj rÃ³Å¼nych przypadkÃ³w gramatycznych.

ANTY-AI â€” zakaz fraz-klisz (BEZWZGLÄ˜DNY ZAKAZ â€” wszystkie tematy, zawsze)

KATEGORIA 1 â€” Zapowiadacze wagi (zamiast nich: podaj fakt wprost)
  "warto zauwaÅ¼yÄ‡ / podkreÅ›liÄ‡ / pamiÄ™taÄ‡ / wiedzieÄ‡ / mieÄ‡ na uwadze"
  "naleÅ¼y podkreÅ›liÄ‡ / zaznaczyÄ‡ / mieÄ‡ Å›wiadomoÅ›Ä‡ / wspomnieÄ‡"
  "co istotne / co waÅ¼ne / co kluczowe / co warte uwagi"
  "kluczowe jest / kluczowym aspektem / kluczowÄ… kwestiÄ…"
  "nie ulega wÄ…tpliwoÅ›ci / nie moÅ¼na zapomnieÄ‡ / nie moÅ¼na pominÄ…Ä‡"
  "istotnym elementem jest / waÅ¼nym elementem jest / istotnÄ… kwestiÄ…"
  âœ… Zamiast: "Warto zauwaÅ¼yÄ‡, Å¼e zakaz trwa 3 lata." â†’ "Zakaz trwa 3 lata."

KATEGORIA 2 â€” Puste przejÅ›cia i zapowiedzi
  "w tym kontekÅ›cie / w kontekÅ›cie powyÅ¼szego / w tym miejscu"
  "przejdÅºmy teraz do / przyjrzyjmy siÄ™ / skupmy siÄ™ na"
  "kolejnym waÅ¼nym aspektem jest / nastÄ™pnym krokiem jest"
  "w dalszej czÄ™Å›ci artykuÅ‚u / jak wspomniano wczeÅ›niej (bez ref.)"
  "to prowadzi do kolejnego aspektu / to rodzi pytanie"
  âœ… Zamiast: "Przyjrzyjmy siÄ™ karom." â†’ H2: "Kary" + pierwsze zdanie z danymi.

KATEGORIA 3 â€” FaÅ‚szywe podsumowania i wnioski
  "podsumowujÄ…c / podsumowujÄ…c powyÅ¼sze / reasumujÄ…c"
  "w Å›wietle powyÅ¼szego / w zwiÄ…zku z powyÅ¼szym / jak widaÄ‡"
  "moÅ¼na zatem stwierdziÄ‡ / naleÅ¼y zatem podkreÅ›liÄ‡"
  "z powyÅ¼szego wynika / wniosek jest nastÄ™pujÄ…cy"
  "to kluczowa rÃ³Å¼nica / to najwaÅ¼niejsza kwestia"
  âœ… Zamiast: "PodsumowujÄ…c, sankcje sÄ… surowe." â†’ ZakoÅ„cz sekcjÄ™ konkretnym faktem.

KATEGORIA 4 â€” Nadmierny formalizm AI
  "kaÅ¼dorazowo naleÅ¼y / kaÅ¼dorazowo warto / kaÅ¼dorazowo wymaga"
  "rekomendowana jest konsultacja / zalecana jest konsultacja"
  "ze wzglÄ™du na zÅ‚oÅ¼onoÅ›Ä‡ / ze wzglÄ™du na specyfikÄ™ tematu"
  "ze wzglÄ™du na powyÅ¼sze okolicznoÅ›ci / majÄ…c na uwadze powyÅ¼sze"
  "w praktyce oznacza to / w praktyce wyglÄ…da to nastÄ™pujÄ…co"
  "naleÅ¼y zwrÃ³ciÄ‡ szczegÃ³lnÄ… uwagÄ™ / wymaga szczegÃ³lnej uwagi"
  âœ… Zamiast: "Ze wzglÄ™du na zÅ‚oÅ¼onoÅ›Ä‡ zagadnienia..." â†’ Podaj konkret.

KATEGORIA 5 â€” Dramatyzatory i teatr
  "Granice sÄ… sztywne." / "SÄ…d patrzy. I sÅ‚ucha." / "I protokÃ³Å‚."
  "To nie jest sprawa na skrÃ³ty." / "Liczy siÄ™ uzasadnienie."
  "W tle zostaje pytanie." / "Prawo nie wybacza."
  KrÃ³tkie zdanie jako dramatyczna pointa â€” ZAKAZ.
  âœ… KrÃ³tkie zdanie = TYLKO twarda liczba lub definicja.

KATEGORIA 6 â€” Placeholder-zdania (wtrÄ…cenia bez treÅ›ci)
  "Istotnym elementem jest [powtÃ³rzenie frazy MUST bez treÅ›ci]."
  "[Encja] jest waÅ¼nym pojÄ™ciem w tym kontekÅ›cie."
  "Temat ten zasÅ‚uguje na szczegÃ³lnÄ… uwagÄ™."
  KaÅ¼de zdanie MUSI dodawaÄ‡ nowÄ… informacjÄ™ â€” nie zapowiadaÄ‡ jej.

KATEGORIA 7 â€” Phantom-placeholder prawny (BEZWZGLÄ˜DNY ZAKAZ)
  âŒ "odpowiednich przepisÃ³w prawa" â€” ZAWSZE podaj konkretny artykuÅ‚: "art. 178a Â§ 1 k.k."
  âŒ "wÅ‚aÅ›ciwych przepisÃ³w" / "stosownych regulacji" / "obowiÄ…zujÄ…cych przepisÃ³w" bez numeru â€” ZAKAZ
  âŒ "zgodnie z przepisami" bez podania jakich â€” ZAKAZ
  âŒ "do 2 lat wiÄ™zienia" dla art. 178a Â§ 1 k.k. â€” BÅÄ„D: nowelizacja 2023 = do 3 lat
  âŒ "recydywa w ciÄ…gu 2 lat" â€” BÅÄ„D: prawo karne nie definiuje recydywy terminem
  âŒ Sygnatura "I C" lub "II C" w kontekÅ›cie konfiskaty pojazdu â€” BÅÄ„D: to sprawa cywilna
  âŒ "mg/100 ml" jako jednostka alkoholu â€” BÅÄ„D: uÅ¼ywaj promili (â€°) lub mg/dmÂ³
  ReguÅ‚a: jeÅ›li nie znasz konkretnego artykuÅ‚u â†’ usuÅ„ zdanie, NIE zastÄ™puj ogÃ³lnikiem.

KATEGORIA 8 â€” Halucynacje terminologiczne w prawie o alkoholu (BEZWZGLÄ˜DNY ZAKAZ)
  âŒ "alkohol z natury" / "alkohol z urodzenia" â€” NONSENS, nie istnieje takie pojÄ™cie
  âŒ "stÄ™Å¼enie alkoholu z natury" / "promile z natury" / "promile z urodzenia" â€” NONSENS
  âŒ "opilstwo" â€” archaizm, nie uÅ¼ywany w aktualnym prawie karnym
  âŒ "pijaÅ„stwo" w kontekÅ›cie prawnym â€” uÅ¼ywaj: "stan nietrzeÅºwoÅ›ci"
  âŒ "obsÅ‚ugiwaÅ‚ pojazd" / "zakaz obsÅ‚ugi pojazdu" â€” BÅÄ„D: uÅ¼ywaj "prowadziÅ‚ pojazd" / "zakaz prowadzenia pojazdu"
  âœ… Poprawna terminologia: "stan po uÅ¼yciu alkoholu" (0,2â€“0,5â€°) | "stan nietrzeÅºwoÅ›ci" (powyÅ¼ej 0,5â€°)
  âœ… Jednostki: promile (â€°) | mg/dmÂ³ w wydychanym powietrzu (NIE: mg/100ml)

ANTY-POWTÃ“RZENIA
ZdefiniowaÅ‚eÅ› pojÄ™cie raz â€” nie definiuj ponownie.
OdwoÅ‚uj siÄ™: "wspomniany wczeÅ›niej X".
Brak powtÃ³rzeÅ„ leksykalnych w sÄ…siednich akapitach.
Brak powielania tej samej konstrukcji skÅ‚adniowej.

ANTY-MYÅšLNIKI
MyÅ›lniki (â€”) stosuj MAX 1 na 3 akapity.
âœ… UÅ¼ywaj przecinkÃ³w, dwukropkÃ³w, nawiasÃ³w, Å›rednikÃ³w.
âŒ "Wyrok â€” choÄ‡ kontrowersyjny â€” zostaÅ‚ utrzymany." (co zdanie)
Nadmiar myÅ›lnikÃ³w = sygnaÅ‚ tekstu AI.

ANTY-PYTANIA-RETORYCZNE
MAX 1 pytanie retoryczne na sekcjÄ™ H2.
âŒ "Jak to wyglÄ…da w praktyce?", "Co to oznacza?", "Czy zawsze?"
âœ… PrzejdÅº bezpoÅ›rednio do informacji.

ANTY-FILLER
KaÅ¼de zdanie MUSI dodawaÄ‡ nowÄ… informacjÄ™.
âŒ Truizmy: "Przewodnik elektryczny przewodzi prÄ…d."
âŒ Puste przejÅ›cia: "To prowadzi do kolejnego aspektu."
âŒ Zapowiedzi: "Kolejna czÄ™Å›Ä‡ artykuÅ‚u wyjaÅ›nia..."
âŒ Puste podsumowania: "To kluczowa rÃ³Å¼nica technologiczna."
âœ… "MiedÅº przewodzi prÄ…d 6Ã— lepiej niÅ¼ Å¼elazo, dlatego stanowi
   60% okablowania domowego."

ANTY-BRAND-STUFFING
Nazwy firm/marek: MAX 2Ã— w caÅ‚ym artykule.

CYTOWANIE Å¹RÃ“DEÅ (YMYL)
âœ… Ustawy, artykuÅ‚y KK/KC/KW, badania, instytucje oficjalne.
âŒ Encje jako ÅºrÃ³dÅ‚a: "Wikipedia podaje...", "WedÅ‚ug [encji]..."
Podawaj fakty bezpoÅ›rednio. Å¹rÃ³dÅ‚o z nazwy â€” MAX 1 raz na artykuÅ‚.

ANTY-HALUCYNACJA
JeÅ›li brak pewnych danych â€” pomiÅ„ lub opisz zasadÄ™ ogÃ³lnie.
âŒ WymyÅ›lone statystyki, rozporzÄ…dzenia, daty, ceny.
âœ… Zasada ogÃ³lna bez numerÃ³w ustaw gdy nie masz pewnoÅ›ci.

POLSZCZYZNA (NKJP, 1,8 mld segmentÃ³w)
â†’ PRZECINKI: obowiÄ…zkowe przed: Å¼e, ktÃ³ry/a/e, poniewaÅ¼, gdyÅ¼,
  aby, Å¼eby, jednak, lecz, ale.
  Brak przecinka przed "Å¼e" = natychmiastowy sygnaÅ‚ AI.
â†’ KOLOKACJE â€” uÅ¼ywaj poprawnych poÅ‚Ä…czeÅ„:
  podjÄ…Ä‡ decyzjÄ™ (NIE: zrobiÄ‡), odnieÅ›Ä‡ sukces (NIE: mieÄ‡),
  popeÅ‚niÄ‡ bÅ‚Ä…d (NIE: zrobiÄ‡), ponieÅ›Ä‡ konsekwencje (NIE: mieÄ‡),
  wysoki poziom (NIE: duÅ¼y), wysokie ryzyko (NIE: duÅ¼e),
  odgrywaÄ‡ rolÄ™ (NIE: peÅ‚niÄ‡), silny bÃ³l (NIE: duÅ¼y),
  rzÄ™sisty deszcz (NIE: duÅ¼y), wysunÄ…Ä‡ propozycjÄ™ (NIE: daÄ‡).
â†’ Unikaj pleonazmÃ³w: "wzajemna wspÃ³Å‚praca",
  "aktualna sytuacja na dziÅ›", "krÃ³tkie streszczenie".
â†’ Mieszaj przypadki gramatyczne â€” nie powtarzaj frazy w mianowniku.

FORMAT
h2:/h3: dla nagÅ‚Ã³wkÃ³w. Zero markdown, HTML, gwiazdek.

</rules>""")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DYNAMIC: SUBJECT POSITION â€” per-batch entity rotation
    # Injected HERE (not in static <rules>) so encja rotates per H2
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    section_lead = pre_batch.get("_section_lead_entity", "")
    main_kw = (pre_batch.get("main_keyword") or {}).get("keyword", "") if isinstance(pre_batch.get("main_keyword"), dict) else str(pre_batch.get("main_keyword") or "")
    if not section_lead:
        section_lead = main_kw

    if section_lead:
        # Build rotation list: lead entity first, then other MUST entities from pre_batch
        must_ents_raw = pre_batch.get("_must_cover_concepts") or pre_batch.get("enhanced", {}).get("must_cover_entities") or []
        must_names = []
        for e in must_ents_raw:
            name = (e.get("text", e.get("entity", "")) if isinstance(e, dict) else str(e)).strip()
            if name and name != section_lead and name not in must_names:
                must_names.append(name)

        # Build rotation instruction
        rotation_entities = [section_lead] + must_names[:3]
        if len(rotation_entities) == 1:
            rotation_str = '"' + section_lead + '"'
        else:
            rotation_str = " | ".join(
                f"akapit {i+1}: \"{e}\"" for i, e in enumerate(rotation_entities)
            )

        fallback_ent = must_names[0] if must_names else "Sad/Sprawca"
        sp_note = "" if section_lead == main_kw else (
            f"\n  (Encja glowna \"{main_kw}\" moze sie pojawiac, ale nie jest podmiotem tej sekcji.)"
        )
        rule_body = (
            "<subject_position_rule>\n"
            f"TEMAT TEJ SEKCJI: \"{section_lead}\"\n"
            f"W tej sekcji H2 kazdy akapit musi miec INNA encje jako podmiot otwierajacy.{sp_note}\n"
            "\n"
            f"ROTACJA PODMIOTOW - kolejnosc akapitow:\n"
            f"  {rotation_str}\n"
            "\n"
            "ZASADA: kazdy kolejny akapit otwiera INNA encja z powyzszej listy jako podmiot gramatyczny.\n"
            "Jesli sekcja ma 4 akapity -> 4 rozne encje jako podmiot pierwszego zdania.\n"
            "\n"
            "Przyklad rotacji (3 akapity):\n"
            f"  Akapit 1: \"{section_lead} [orzeczenie]...\"\n"
            f"  Akapit 2: \"{fallback_ent} [orzeczenie]...\"\n"
            "  Akapit 3: Liczba/fakt na poczatku lub kolejna encja MUST\n"
            "\n"
            "ZAKAZ: dwa akapity z rzedu otwarte ta sama encja.\n"
            "ZAKAZ: 'Istotnym aspektem jest [encja]...' - to orzecznik, nie podmiot.\n"
            "ZAKAZ: 'Zgodnie z przepisami o [encja]...' - to dopelnienie, nie podmiot.\n"
            "\n"
            "Google salience: podmiot x pozycja = 3-6x wyzszy wynik niz encja w dopelnieniu.\n"
            "Rotacja podmiotow = naturalne pokrycie wszystkich kluczowych encji tematu.\n"
            "</subject_position_rule>"
        )
        parts.append(rule_body)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # FEW-SHOT EXAMPLES
    # (Anthropic/OpenAI: przykÅ‚ady skuteczniejsze niÅ¼ instrukcje)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    parts.append("""<examples>

PRZYKÅAD ZÅY â€” czego NIE pisaÄ‡:
<example_bad>
Jazda po alkoholu to powaÅ¼ne przestÄ™pstwo w Polsce. SÄ…d patrzy. I sÅ‚ucha.
Granice sÄ… sztywne. Kancelaria posiada duÅ¼e doÅ›wiadczenie w sprawach
karnych ruchu drogowego. Kancelaria posiada duÅ¼e doÅ›wiadczenie w sprawach
karnych ruchu drogowego. Ta instytucja daje sÄ…dowi moÅ¼liwoÅ›Ä‡ odstÄ…pienia
od wymierzenia Å›rodka, co warto zauwaÅ¼yÄ‡ i naleÅ¼y podkreÅ›liÄ‡.
</example_bad>
BÅ‚Ä™dy: dramatyzatory ("SÄ…d patrzy. I sÅ‚ucha."), powtÃ³rzenie zdania 2Ã—,
frazy AI ("warto zauwaÅ¼yÄ‡"), brak liczb, puste stwierdzenia.

PRZYKÅAD DOBRY â€” tak pisz:
<example_good>
Skazanie z art. 178a Â§ 1 KK grozi pozbawieniem wolnoÅ›ci do 3 lat
oraz obligatoryjnym zakazem prowadzenia pojazdÃ³w od 3 do 15 lat.
SÄ…d nie ma tu uznaniowoÅ›ci â€” zakaz jest obowiÄ…zkowy przy kaÅ¼dym
wyroku skazujÄ…cym, niezaleÅ¼nie od okolicznoÅ›ci Å‚agodzÄ…cych.
JedynÄ… zmiennÄ… pozostaje jego wymiar, ktÃ³ry sÄ…d ustala biorÄ…c pod
uwagÄ™ stopieÅ„ zawinienia i dotychczasowÄ… karalnoÅ›Ä‡ sprawcy.
</example_good>
Zalety: konkretny artykuÅ‚ KK, konkretne liczby (3 lata, 3â€“15 lat),
kauzalnoÅ›Ä‡ (obligatoryjny â†’ brak uznaniowoÅ›ci â†’ jedyna zmienna),
zero fraz AI, zero powtÃ³rzeÅ„.

</examples>""")

    return "\n\n".join(parts)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Schema guard â€” field validation
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_CRITICAL_FIELDS = [
    "keywords",             # keyword list: without this, article has no SEO
    "main_keyword",         # primary keyword
    "batch_number",         # batch sequencing
]
_IMPORTANT_FIELDS = [
    "gpt_instructions_v39", # backend writing instructions
    "enhanced",             # enhanced_pre_batch AI data
    "h2_remaining",         # H2 structure
    "article_memory",       # context from previous batches
    "keyword_limits",       # STOP/EXCEEDED rules
    "coverage",             # keyword coverage state
]

def _schema_guard(pre_batch):
    """Validate pre_batch has critical fields. Log warnings for missing."""
    missing_critical = [f for f in _CRITICAL_FIELDS if f not in pre_batch or pre_batch[f] is None]
    missing_important = [f for f in _IMPORTANT_FIELDS if f not in pre_batch or pre_batch[f] is None]

    if missing_critical:
        _pb_logger.warning(
            f"âš ï¸ SCHEMA GUARD: Missing CRITICAL fields: {missing_critical}. "
            f"Backend may have changed API. Article quality will be degraded."
        )
    if missing_important:
        _pb_logger.info(
            f"â„¹ï¸ Schema guard: Missing optional fields: {missing_important} "
            f"(batch {pre_batch.get('batch_number', '?')})"
        )

    # Validate enhanced sub-fields if enhanced exists
    enhanced = pre_batch.get("enhanced") or {}
    if enhanced:
        expected_enhanced = [
            "smart_instructions_formatted", "causal_context",
            "information_gain", "relations_to_establish"
        ]
        missing_enh = [f for f in expected_enhanced if not enhanced.get(f)]
        if missing_enh:
            _pb_logger.info(f"â„¹ï¸ Enhanced missing: {missing_enh}")


def build_user_prompt(pre_batch, h2, batch_type, article_memory=None):
    """
    Main user prompt builder.
    Converts ALL pre_batch fields into readable, actionable instructions.
    Each section is wrapped in try/except so one bad field won't crash generation.
    """
    pre_batch = pre_batch or {}
    sections = []

    # â”€â”€ RE-ANCHOR: krÃ³tkie przypomnienie roli (dokumentacja Anthropic: re-anchor w user prompcie) â”€â”€
    # Dla YMYL dodaje ostrzeÅ¼enie o weryfikacji wyrokÃ³w
    detected_category = pre_batch.get("detected_category", "")
    if detected_category == "prawo":
        sections.append(
            "Piszesz jako redaktor naczelny â€” ton formalny, zero frywolnoÅ›ci. "
            "Wyroki cytuj TYLKO jeÅ›li sygnatura pasuje do gaÅ‚Ä™zi prawa artykuÅ‚u "
            "(II K/AKa = karne, I C/ACa = cywilne). SzczegÃ³Å‚owe zasady w system prompcie."
        )
    elif detected_category in ("medycyna", "finanse"):
        sections.append(
            "Piszesz jako redaktor naczelny â€” ton formalny, precyzyjny. "
            "Cytuj TYLKO pewne dane. SzczegÃ³Å‚owe zasady w system prompcie."
        )
    else:
        sections.append(
            "Piszesz jako redaktor naczelny â€” rzeczowo, bez frywolnoÅ›ci. "
            "SzczegÃ³Å‚owe zasady w system prompcie."
        )

    # â”€â”€ OPENING PATTERN â€” per-batch rotation (zapobiega identycznym otwarciom sekcji) â”€â”€
    _OPENING_PATTERNS = [
        ("A", "LICZBA/FAKT",
         "Zacznij sekcje od konkretnej liczby, daty lub wartosci. Np: '3 lata - tyle wynosi...', 'Od 2500 do 30 000 zl...'"),
        ("B", "WARUNEK",
         "Zacznij sekcje od warunku lub progu. Np: 'Gdy stezenie przekracza...', 'Jesli kierowca...', 'Przy kazdym kolejnym...'"),
        ("C", "SKUTEK WPROST",
         "Zacznij sekcje od konsekwencji. Np: 'Konfiskata grozi kazdemu...', 'Zakaz trwa od 3 do 15 lat - sad nie moze...'"),
        ("D", "KONTRAST",
         "Zacznij sekcje od rozroznienia. Np: 'Wykroczenie i przestepstwo - granica przebiega...', 'Recydywista odpowiada inaczej...'"),
        ("E", "PODMIOT+ORZECZENIE",
         "Zacznij sekcje klasycznie: podmiot + orzeczenie z konkretem. Np: 'Stan po uzyciu alkoholu to poziom 0,2-0,5 promila...'"),
        ("F", "PYTANIE+ODPOWIEDZ",
         "Zacznij sekcje pytaniem z natychmiastowa odpowiedzia. Np: 'Czy mozna unikac zakazu? Tak, ale tylko gdy...'"),
    ]
    batch_num = pre_batch.get("batch_number", 1) or 1
    if batch_type in ("INTRO", "intro"):
        pattern_idx = 4  # INTRO: podmiot+orzeczenie â€” lead zaczyna od definicji/odpowiedzi
    else:
        pattern_idx = (batch_num - 1) % len(_OPENING_PATTERNS)
    p_letter, p_name, p_desc = _OPENING_PATTERNS[pattern_idx]
    sections.append(
        f"OTWARCIE TEJ SEKCJI â€” wzorzec {p_letter} ({p_name}):\n"
        f"{p_desc}\n"
        f"ZAKAZ: nie zaczynaj od encji jako podmiotu w stylu '[X] jest/to/oznacza' â€” to wzorzec juÅ¼ uÅ¼yty w poprzednich sekcjach."
    )

    # â”€â”€ SCHEMA GUARD: validate critical fields from backend â”€â”€
    _schema_guard(pre_batch)

    formatters = [
        # â”€â”€ TIER 1: NON-NEGOTIABLE (backend hard rules) â”€â”€
        lambda: _fmt_batch_header(pre_batch, h2, batch_type),
        lambda: _fmt_keywords(pre_batch),           # MUST/STOP/EXCEEDED: hardest constraints
        lambda: _fmt_smart_instructions(pre_batch),  # enhanced_pre_batch AI instructions
        lambda: _fmt_legal_medical(pre_batch),        # YMYL: legal compliance, non-negotiable

        # â”€â”€ TIER 2: BACKEND WRITE INSTRUCTIONS (gpt_instructions_v39 etc.) â”€â”€
        lambda: _fmt_semantic_plan(pre_batch, h2),
        lambda: _fmt_coverage_density(pre_batch),
        lambda: _fmt_phrase_hierarchy(pre_batch),
        lambda: _fmt_continuation(pre_batch),
        lambda: _fmt_article_memory(article_memory),
        lambda: _fmt_h2_remaining(pre_batch),

        # â”€â”€ TIER 3: CONTENT CONTEXT (enrichment data) â”€â”€
        lambda: _fmt_entity_salience(pre_batch),     # entity positioning rules (salience only)
        # _fmt_entities REMOVED v45.4.1: gpt_instructions_v39 already contains
        # curated "ğŸ§  ENCJE:" section (max 3/batch, importanceâ‰¥0.7, with HOW hints).
        # Our version duplicated it with dirtier, unfiltered data from S1.
        # _fmt_ngrams REMOVED v45.4.1: raw statistical n-grams from competitor
        # pages often contain CSS/JS artifacts ("button button", "block embed").
        # Custom GPT never sees these and produces better text without them.
        lambda: _fmt_serp_enrichment(pre_batch),
        lambda: _fmt_causal_context(pre_batch),
        lambda: _fmt_depth_signals(pre_batch),       # depth signals when previous batch scored low
        lambda: _fmt_experience_markers(pre_batch),
        lambda: _fmt_natural_polish(pre_batch),      # v50: fleksja, spacing, anti-stuffing

        # â”€â”€ TIER 4: SOFT GUIDELINES (format, style, intro) â”€â”€
        lambda: _fmt_intro_guidance(pre_batch, batch_type),
        lambda: _fmt_style(pre_batch),
        lambda: _fmt_output_format(h2, batch_type),
    ]

    for fmt in formatters:
        try:
            result = fmt()
            if result:
                sections.append(result)
        except Exception:
            pass

    return "\n\n".join(sections)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION FORMATTERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _fmt_batch_header(pre_batch, h2, batch_type):
    batch_number = pre_batch.get("batch_number", 1)
    total_batches = pre_batch.get("total_planned_batches", 1)
    batch_length = pre_batch.get("batch_length") or {}

    min_w = batch_length.get("min_words", 350)
    max_w = batch_length.get("max_words", 500)

    section_length = pre_batch.get("section_length_guidance") or {}
    length_hint = ""
    if section_length:
        suggested = section_length.get("suggested_words") or section_length.get("target_words")
        if suggested:
            length_hint = f"\nSugerowana dÅ‚ugoÅ›Ä‡ tej sekcji: ~{suggested} sÅ‚Ã³w."

    h2_instruction = ""
    if batch_type not in ("INTRO", "intro"):
        h2_instruction = f"\nZaczynaj DOKÅADNIE od: h2: {h2}"

    return f"""â•â•â• BATCH {batch_number}/{total_batches}: {batch_type} â•â•â•
Sekcja H2: "{h2}"
DÅ‚ugoÅ›Ä‡: {min_w}-{max_w} sÅ‚Ã³w{length_hint}{h2_instruction}"""


def _fmt_intro_guidance(pre_batch, batch_type):
    """Build the LEAD paragraph prompt â€” the article's answer-first introduction.

    The lead must:
    1. Directly answer the featured snippet question OR complement AI Overview
    2. Contain the main keyword in the first sentence
    3. Be a self-contained mini-article (readable without scrolling)
    4. Promise deeper content to encourage further reading
    """
    if batch_type not in ("INTRO", "intro"):
        return ""
    guidance = pre_batch.get("intro_guidance", "")

    main_kw = pre_batch.get("main_keyword") or {}
    kw_name = main_kw.get("keyword", "") if isinstance(main_kw, dict) else str(main_kw)

    # â”€â”€ Extract SERP signals â”€â”€
    serp = pre_batch.get("serp_enrichment") or {}

    # Featured snippet (position 0)
    fs_raw = serp.get("featured_snippet") or {}
    if isinstance(fs_raw, dict):
        fs_text = fs_raw.get("text", "") or fs_raw.get("snippet", "") or ""
        fs_type = fs_raw.get("type", "paragraph")  # paragraph / list / table
    elif isinstance(fs_raw, str):
        fs_text = fs_raw
        fs_type = "paragraph"
    else:
        fs_text = ""
        fs_type = "paragraph"

    # AI Overview
    ai_ov_raw = serp.get("ai_overview") or {}
    if isinstance(ai_ov_raw, dict):
        ai_ov_text = ai_ov_raw.get("text", "") or ai_ov_raw.get("summary", "") or ""
    elif isinstance(ai_ov_raw, str):
        ai_ov_text = ai_ov_raw
    else:
        ai_ov_text = ""

    # Search intent
    search_intent = serp.get("search_intent") or ""

    # Competitor titles â€” reveal what TOP10 promises
    comp_titles = serp.get("competitor_titles") or []

    # â”€â”€ Determine lead strategy based on available SERP data â”€â”€
    has_snippet = bool(fs_text and len(fs_text) > 30)
    has_ai_overview = bool(ai_ov_text and len(ai_ov_text) > 50)

    parts = [
        "â•â•â• LEAD / WSTÄ˜P ARTYKUÅU â•â•â•",
        "Piszesz LEAD â€” pierwszÄ… rzecz, ktÃ³rÄ… widzi czytelnik po klikniÄ™ciu w artykuÅ‚.",
        "Lead NIE jest zapowiedziÄ… artykuÅ‚u. Lead JEST odpowiedziÄ… na pytanie uÅ¼ytkownika.",
        "",
        "ENCJA GÅÃ“WNA â€” DEFINICJA W PIERWSZYM ZDANIU (KRYTYCZNE DLA NLP):",
        f'Pierwsze zdanie MUSI zawieraÄ‡ jednoznacznÄ… definicjÄ™ encji gÅ‚Ã³wnej "{kw_name}".',
        "Wzorzec: \"[Encja gÅ‚Ã³wna] to [definicja jednozdaniowa]\" â€” Google NLP klasyfikuje encjÄ™",
        "na podstawie PIERWSZEGO zdania w dokumencie. Brak definicji = niÅ¼sza salience.",
        'PrzykÅ‚ad: "Witaminy na skÃ³rÄ™ to grupa skÅ‚adnikÃ³w odÅ¼ywczych, ktÃ³re wspierajÄ… regeneracjÄ™ naskÃ³rka i spowalniajÄ… procesy starzenia."',
        "",
        "HAK CZYTELNICZY (zdanie 2-3 leadu):",
        "Po definicji dodaj 2-3 zdania, ktÃ³re powiedzÄ… czytelnikowi DLACZEGO ma to czytaÄ‡.",
        "Wzorzec: osobiste odwoÅ‚anie + obietnica wartoÅ›ci.",
        'PrzykÅ‚ad: "Twoja skÃ³ra to lustro Twojego metabolizmu. SprawdÅº, jak mÄ…dra suplementacja i dieta mogÄ… odbudowaÄ‡ barierÄ™ ochronnÄ… i zatrzymaÄ‡ fotostarzenie."',
        "NIE pisz: 'W niniejszym artykule...', 'PoniÅ¼ej przedstawiamy...', 'Zapraszamy do lektury...'",
    ]

    # â”€â”€ STRATEGY A: Featured snippet exists â†’ beat it â”€â”€
    if has_snippet:
        parts.append("")
        parts.append("â•â•â• FEATURED SNIPPET (pozycja 0 w Google) â•â•â•")
        parts.append("Google wyÅ›wietla tÄ™ odpowiedÅº NAD wynikami organicznymi:")
        parts.append(f"  Â« {fs_text[:500]} Â»")
        if fs_type == "list":
            parts.append("  (typ: lista punktowa)")
        parts.append("")
        parts.append("STRATEGIA: TwÃ³j lead musi BIÄ† ten snippet.")
        parts.append("  â€¢ Zdanie 1-2: Daj tÄ™ samÄ… odpowiedÅº, ale LEPSZÄ„ â€” precyzyjniejszÄ…, aktualniejszÄ…, z konkretnÄ… liczbÄ…/datÄ….")
        parts.append("  â€¢ Zdanie 3-4: Dodaj kontekst, ktÃ³rego snippet NIE zawiera (rok, zmiana prawa, wyjÄ…tek, skala zjawiska).")
        parts.append("  â€¢ Zdanie 5-7: ZapowiedÅº gÅ‚Ä™bi â€” dlaczego warto czytaÄ‡ dalej (bez listy H2!).")
        parts.append("  Cel: Google powinien zastÄ…piÄ‡ obecny snippet TWOIM leadem.")

    # â”€â”€ STRATEGY B: AI Overview exists â†’ complement it â”€â”€
    if has_ai_overview:
        parts.append("")
        parts.append("â•â•â• GOOGLE AI OVERVIEW â•â•â•")
        parts.append("Google generuje uÅ¼ytkownikom tÄ™ odpowiedÅº AI ZANIM kliknÄ… w wyniki:")
        parts.append(f"  Â« {ai_ov_text[:500]} Â»")
        parts.append("")
        if has_snippet:
            parts.append("AI Overview pokrywa siÄ™ z featured snippet. TwÃ³j lead musi wnosiÄ‡ WIÄ˜CEJ:")
        else:
            parts.append("STRATEGIA: UÅ¼ytkownik juÅ¼ przeczytaÅ‚ to podsumowanie AI.")
        parts.append("  â€¢ NIE powtarzaj tych samych informacji â€” czytelnik juÅ¼ je zna.")
        parts.append("  â€¢ Zacznij od odpowiedzi, ale natychmiast dodaj fakt/liczbÄ™/kontekst,")
        parts.append("    ktÃ³rego AI Overview nie podaje.")
        parts.append("  â€¢ PokaÅ¼, Å¼e artykuÅ‚ idzie GÅÄ˜BIEJ niÅ¼ AI Overview.")

    # â”€â”€ STRATEGY C: No SERP signals â†’ pure answer-first â”€â”€
    if not has_snippet and not has_ai_overview:
        parts.append("")
        parts.append("Brak featured snippet i AI Overview â€” TwÃ³j lead ma szansÄ™ STAÄ† SIÄ˜ snippetem!")
        parts.append("  â€¢ Zdanie 1-2: BezpoÅ›rednia, zwiÄ™zÅ‚a odpowiedÅº na pytanie z frazy kluczowej.")
        parts.append("  â€¢ Zdanie 3-4: Konkretna liczba, data lub fakt â€” kontekst.")
        parts.append("  â€¢ Zdanie 5-7: ZapowiedÅº gÅ‚Ä™bi artykuÅ‚u.")
        parts.append("  Google wyciÄ…gnie Twoje pierwsze 2-3 zdania jako snippet, jeÅ›li bÄ™dÄ… answer-first.")

    # â”€â”€ Search intent guidance â”€â”€
    if search_intent:
        parts.append(f"\nIntencja wyszukiwania: {search_intent}")
        if "informacyjn" in search_intent.lower() or "information" in search_intent.lower():
            parts.append("â†’ Lead musi odpowiedzieÄ‡ CO/JAK/DLACZEGO w pierwszym zdaniu.")
        elif "transakcyjn" in search_intent.lower() or "transaction" in search_intent.lower():
            parts.append("â†’ Lead musi szybko podaÄ‡ rozwiÄ…zanie/produkt/krok do dziaÅ‚ania.")
        elif "nawigacyjn" in search_intent.lower() or "navigation" in search_intent.lower():
            parts.append("â†’ Lead musi od razu wskazaÄ‡ gdzie/jak dotrzeÄ‡ do celu.")

    # â”€â”€ Competitor titles â€” what TOP10 promises â”€â”€
    if comp_titles:
        titles_str = " | ".join(comp_titles[:5])
        parts.append(f"\nTytuÅ‚y TOP5 w Google: {titles_str}")
        parts.append("â†’ TwÃ³j lead musi obiecywaÄ‡ to, co konkurencja obiecuje w tytuÅ‚ach, ALE z konkretem.")

    # â”€â”€ Answer-first structure â”€â”€
    parts.append("")
    parts.append("â•â•â• STRUKTURA LEADU â•â•â•")
    if kw_name:
        parts.append(f'Fraza gÅ‚Ã³wna: "{kw_name}" â€” MUSI pojawiÄ‡ siÄ™ w pierwszym zdaniu.')
    parts.append("""
AKAPIT 1 â€” DEFINICJA + ODPOWIEDÅ¹ (3-4 zdania, ~60 sÅ‚Ã³w):
  Zdanie 1: JEDNOZNACZNA DEFINICJA encji gÅ‚Ã³wnej z frazÄ… kluczowÄ….
    Wzorzec: "[Fraza kluczowa] to [co to jest / do czego sÅ‚uÅ¼y]."
    To zdanie trafia do featured snippet / AI Overview.
  Zdanie 2-3: UzupeÅ‚nienie z konkretnÄ… liczbÄ…/datÄ…/faktem.

AKAPIT 2 â€” HAK + KONTEKST (2-3 zdania, ~50 sÅ‚Ã³w):
  Zdanie otwierajÄ…ce: dlaczego ten temat jest istotny w praktyce.
  Kolejne zdania: skala zjawiska, zmiana prawa, trend.
  Jeden konkretny fakt, ktÃ³rego nie ma w snippet/AI overview.

AKAPIT 3 â€” ZACHÄ˜TA DO CZYTANIA (1-2 zdania, ~30 sÅ‚Ã³w):
  Co czytelnik znajdzie dalej? Bez listy H2.
  Np. "PoniÅ¼ej â€” krok po kroku procedura z wzorami pism i aktualnymi kosztami."
""")

    # â”€â”€ Style rules â”€â”€
    parts.append("REGUÅY STYLISTYCZNE LEADU:")
    parts.append("  â€¢ KaÅ¼de zdanie: max 20 sÅ‚Ã³w")
    parts.append("  â€¢ Max 2 przecinki w jednym zdaniu")
    parts.append("  â€¢ ZAKAZ zdaÅ„ wielokrotnie zÅ‚oÅ¼onych ('ktÃ³ry... poniewaÅ¼... a takÅ¼e...')")
    parts.append("  â€¢ ZAKAZ fraz: 'W dzisiejszych czasach', 'Warto zaznaczyÄ‡', 'NaleÅ¼y podkreÅ›liÄ‡',")
    parts.append("    'PoniÅ¼szy artykuÅ‚', 'W niniejszym tekÅ›cie', 'Zapraszamy do lektury'")
    parts.append("  â€¢ ZAKAZ nagÅ‚Ã³wka h2: (lead nie ma nagÅ‚Ã³wka)")
    parts.append("  â€¢ DÅ‚ugoÅ›Ä‡: 120-200 sÅ‚Ã³w (3 krÃ³tkie akapity)")
    parts.append("  â€¢ Ton: rzeczowy, bez dramatyzowania, bez clickbaitu")
    parts.append("  â€¢ ZAKAZ formy 'Ty/TwÃ³j' i 2. osoby ('mÃ³wisz', 'wchodzisz', 'musisz') â€” pisz w 3. osobie lub bezosobowo")
    parts.append("  â€¢ Pisz jak ekspert, nie jak copywriter â€” fakty > obietnice")

    # â”€â”€ Custom intro guidance from backend â”€â”€
    if guidance:
        parts.append("")
        if isinstance(guidance, dict):
            hook = guidance.get("hook", "")
            angle = guidance.get("angle", "")
            if hook:
                parts.append(f"Hak otwierajÄ…cy: {hook}")
            if angle:
                parts.append(f"KÄ…t artykuÅ‚u: {angle}")
        else:
            parts.append(str(guidance))

    return "\n".join(parts)


def _fmt_smart_instructions(pre_batch):
    """Smart instructions from enhanced_pre_batch : THE most valuable field."""
    enhanced = pre_batch.get("enhanced") or {}
    smart = enhanced.get("smart_instructions_formatted", "")
    if smart:
        return f"â•â•â• INSTRUKCJE DLA TEGO BATCHA â•â•â•\n{smart[:1000]}"
    return ""


def _parse_target_max(target_total_str):
    """
    Parse target_max from backend's target_total field.
    Backend sends target_total as "min-max" string (e.g., "2-6").
    Returns max value as int, or 0 if unparseable.
    """
    if not target_total_str:
        return 0
    if isinstance(target_total_str, (int, float)):
        return int(target_total_str)
    try:
        parts = str(target_total_str).replace("x", "").split("-")
        if len(parts) >= 2:
            return int(parts[-1].strip())
        return int(parts[0].strip())
    except (ValueError, IndexError):
        return 0


def _fmt_keywords(pre_batch):
    """
    Format keywords section with CALCULATED remaining_max.
    
    v1.1: Backend sends actual (current uses) and target_total ("min-max")
    but NOT remaining. We calculate: remaining = target_max - actual.
    Also shows hard_max_this_batch so Claude knows per-batch limits.
    """
    keywords_info = pre_batch.get("keywords") or {}
    keyword_limits = pre_batch.get("keyword_limits") or {}
    soft_caps = pre_batch.get("soft_cap_recommendations") or {}

    # Bug B Fix: Gdy globalny budzet main keyword wyczerpany â€” nie wstrzykuj go jako MUST
    _kw_global_remaining = pre_batch.get("_kw_global_remaining", None)
    _kw_global_used = pre_batch.get("_kw_global_used", None)
    _main_kw_budget_exhausted = (
        _kw_global_remaining is not None and _kw_global_remaining == 0
    )

    # Bug B Fix: Wyciagnij nazwe main keyword do porownania w petli
    _raw_main_kw = pre_batch.get("main_keyword") or {}
    main_kw = _raw_main_kw.get("keyword", "") if isinstance(_raw_main_kw, dict) else str(_raw_main_kw)

    # â”€â”€ MUST USE (with calculated remaining) â”€â”€
    must_raw = keywords_info.get("basic_must_use", [])
    must_lines = []
    _budget_exhausted_kws = []  # Bug B Fix: kw przeniesione z MUST do STOP
    for kw in must_raw:
        if isinstance(kw, dict):
            name = kw.get("keyword", "")

            # Bug B Fix: Gdy globalny budzet main keyword = 0, przenosimy go do STOP
            if _main_kw_budget_exhausted and name and main_kw and \
               name.lower() == main_kw.lower():
                _budget_exhausted_kws.append(name)
                continue  # nie dodawaj do MUST

            # Calculate remaining from actual + target_total
            actual = kw.get("actual", kw.get("actual_uses", kw.get("current_count", 0)))
            target_total = kw.get("target_total", "")
            target_max = _parse_target_max(target_total) or kw.get("target_max", 0)
            hard_max = kw.get("hard_max_this_batch", "")
            use_range = kw.get("use_this_batch", "")

            # Explicit remaining from backend (if sent), otherwise calculate
            remaining = kw.get("remaining", kw.get("remaining_max", ""))
            if not remaining and target_max and isinstance(actual, (int, float)):
                remaining = max(0, target_max - int(actual))

            # Build descriptive line
            parts_line = [f'"{name}"']
            if remaining:
                parts_line.append(f"zostaÅ‚o {remaining}Ã— ogÃ³Å‚em")
            if hard_max:
                parts_line.append(f"max {hard_max}Ã— w tym batchu")
            elif use_range:
                parts_line.append(f"cel: {use_range}Ã— w tym batchu")

            must_lines.append(f'  â€¢ {", ".join(parts_line)}')
        else:
            must_lines.append(f'  â€¢ "{kw}"')

    # â”€â”€ EXTENDED (with remaining) â”€â”€
    ext_raw = keywords_info.get("extended_this_batch", [])
    ext_lines = []
    for kw in ext_raw:
        if isinstance(kw, dict):
            name = kw.get("keyword", "")
            actual = kw.get("actual", kw.get("actual_uses", 0))
            target_total = kw.get("target_total", "")
            target_max = _parse_target_max(target_total) or kw.get("target_max", 0)
            remaining = kw.get("remaining", kw.get("remaining_max", ""))
            if not remaining and target_max and isinstance(actual, (int, float)):
                remaining = max(0, target_max - int(actual))
            
            line = f'  â€¢ "{name}"'
            if remaining:
                line += f" , zostaÅ‚o {remaining}Ã—"
            ext_lines.append(line)
        else:
            ext_lines.append(f'  â€¢ "{kw}"')

    # â”€â”€ STOP â”€â”€
    stop_raw = keyword_limits.get("stop_keywords") or []
    stop_lines = []
    for s in stop_raw:
        if isinstance(s, dict):
            name = s.get("keyword", "")
            current = s.get("current_count", s.get("current", s.get("actual", "?")))
            max_c = s.get("max_count", s.get("max", s.get("target_max", "?")))
            stop_lines.append(f'  â€¢ "{name}" (juÅ¼ {current}Ã—, limit {max_c}) , STOP!')
        else:
            stop_lines.append(f'  â€¢ "{s}"')

    # Bug B Fix: Dodaj main keyword do STOP gdy globalny budzet = 0
    for exhausted_kw in _budget_exhausted_kws:
        stop_lines.append(f'  â€¢ "{exhausted_kw}" (limit globalny 6Ã— osiÄ…gniÄ™ty â€” NIE UÅ»YWAJ w tym batchu!)')

    # â”€â”€ CAUTION â”€â”€
    caution_raw = keyword_limits.get("caution_keywords") or []
    caution_lines = []
    for c in caution_raw:
        if isinstance(c, dict):
            name = c.get("keyword", "")
            current = c.get("current_count", c.get("current", c.get("actual", "")))
            max_c = c.get("max_count", c.get("max", c.get("target_max", "")))
            line = f'  â€¢ "{name}"'
            if current and max_c:
                line += f" ({current}/{max_c})"
            line += " , max 1Ã— w tym batchu"
            caution_lines.append(line)
        else:
            caution_lines.append(f'  â€¢ "{c}" , max 1Ã—')

    # â”€â”€ SOFT CAPS â”€â”€
    soft_notes = []
    if soft_caps:
        for kw_name, info in soft_caps.items():
            if isinstance(info, dict):
                action = info.get("action", "")
                if action and action != "OK":
                    soft_notes.append(f'  â„¹ï¸ "{kw_name}": {action}')

    # v56: Hard keyword ban when overflow ceiling reached (>150% target)
    _kw_force_ban = pre_batch.get("_kw_force_ban", False)
    if _kw_force_ban and main_kw:
        # Remove main keyword from MUST entirely and add extreme prohibition
        must_lines = [l for l in must_lines if main_kw.lower() not in l.lower()]

    # â”€â”€ Build section â”€â”€
    parts = ["â•â•â• FRAZY KLUCZOWE â•â•â•"]

    # v56: ABSOLUTE BAN block â€” appears first, impossible to miss
    if _kw_force_ban and main_kw:
        parts.append(f'â›”â›”â›” ABSOLUTNY ZAKAZ: Fraza "{main_kw}" jest PRZEKROCZONA Ã—4.')
        parts.append(f'NIE PISZ "{main_kw}" ANI RAZ w tym batchu. UÅ¼yj zaimkÃ³w (to, tego, tym) lub synonimÃ³w.')
        parts.append(f'KaÅ¼de uÅ¼ycie "{main_kw}" w tym batchu = keyword stuffing = kara Google.\n')

    if must_lines:
        parts.append("ğŸ”´ OBOWIÄ„ZKOWE (wpleÄ‡ naturalnie w tekst):")
        parts.extend(must_lines)

    if ext_lines:
        parts.append("\nğŸŸ¡ ROZSZERZONE (uÅ¼yj jeÅ›li pasujÄ… do kontekstu):")
        parts.extend(ext_lines)

    if stop_lines:
        parts.append("\nğŸ›‘ STOP, NIE UÅ»YWAJ (przekroczone limity!):")
        parts.extend(stop_lines)

    if caution_lines:
        parts.append("\nâš ï¸ OSTROÅ»NIE, uÅ¼yj max 1Ã— lub pomiÅ„:")
        parts.extend(caution_lines)

    if soft_notes:
        parts.append("")
        parts.extend(soft_notes)

    return "\n".join(parts) if len(parts) > 1 else ""


def _fmt_semantic_plan(pre_batch, h2):
    plan = pre_batch.get("semantic_batch_plan") or {}
    if not plan:
        return ""

    parts = ["â•â•â• CO PISAÄ† W TEJ SEKCJI (tematy do pokrycia) â•â•â•"]

    h2_coverage = plan.get("h2_coverage") or {}
    for h2_name, info in h2_coverage.items():
        if isinstance(info, dict):
            angle = info.get("semantic_angle", "")
            must = info.get("must_phrases", [])
            if angle:
                parts.append(f'KÄ…t semantyczny: {angle}')
            if must:
                phrases = ", ".join(f'"{p}"' for p in must[:5])
                parts.append(f'ObowiÄ…zkowe frazy w tej sekcji: {phrases}')

    density_targets = plan.get("density_targets") or {}
    overall = density_targets.get("overall")
    if overall:
        parts.append(f'Docelowa gÄ™stoÅ›Ä‡ fraz: {overall}%')

    direction = plan.get("content_direction") or plan.get("writing_direction", "")
    if direction:
        parts.append(f'Kierunek treÅ›ci: {direction}')

    return "\n".join(parts) if len(parts) > 1 else ""


def _fmt_entity_salience(pre_batch):
    """Entity salience instructions : grammatical positioning, hierarchy.
    
    Based on:
    - Patent US10235423B2 (entity metrics)
    - Patent US9251473B2 (salient items in documents)
    - Dunietz & Gillick (2014) entity salience research
    - Google Cloud NLP API salience scoring
    
    v47.0: Also includes backend placement instructions from competitor analysis
    (entity_salience.py in gpt-ngram-api: salience scoring, co-occurrence, placement)
    
    Data sources:
    - pre_batch["_entity_salience_instructions"] : local positioning rules (from entity_salience.py frontend)
    - pre_batch["_backend_placement_instruction"] : backend placement from competitor analysis
    - pre_batch["_concept_instruction"] : topical concepts agent instruction
    - pre_batch["_must_cover_concepts"] : concept entities that must be covered
    """
    parts = []
    
    # 1. Local salience positioning rules
    local_instructions = pre_batch.get("_entity_salience_instructions", "")
    if local_instructions:
        parts.append(local_instructions)
    
    # 2. v47.0: Backend placement instructions (from gpt-ngram-api competitor analysis)
    backend_placement = pre_batch.get("_backend_placement_instruction", "")
    if backend_placement:
        parts.append("â•â•â• ROZMIESZCZENIE ENCJI (z analizy konkurencji) â•â•â•")
        parts.append(
            "âš ï¸ TO SÄ„ WSKAZÃ“WKI TECHNICZNE â€” NIE kopiuj ich dosÅ‚ownie do tekstu!\n"
            "UÅ¼yj jako inspiracjÄ™/tÅ‚o. Pisz wÅ‚asne zdania. Nie przepisuj fragmentÃ³w poniÅ¼ej."
        )
        parts.append(backend_placement)
    
    # 3. v47.0: Concept instruction + must-cover concepts
    # v52.1: Dodano instrukcjÄ™ fleksji â€” encje podawane sÄ… w mianowniku, Claude musi je odmieniaÄ‡
    FLEXION_NOTE = (
        "\nâš ï¸ FLEKSJA: PojÄ™cia sÄ… w mianowniku â€” odmieniaj je przez przypadki zaleÅ¼nie od kontekstu. "
        'Np. "gaÅ‚ka meblowa" â†’ "gaÅ‚ki meblowej" (dop.), "gaÅ‚kÄ™ meblowÄ…" (bier.). '
        "Gramatyczna poprawnoÅ›Ä‡ > dosÅ‚owne powtÃ³rzenie formy bazowej."
    )
    concept_instr = pre_batch.get("_concept_instruction", "")
    must_concepts = pre_batch.get("_must_cover_concepts", [])
    if concept_instr:
        parts.append(concept_instr + FLEXION_NOTE)
    elif must_concepts:
        # Build instruction from concept list if no agent instruction provided
        concept_names = [c.get("text", c) if isinstance(c, dict) else str(c) for c in must_concepts[:10]]
        parts.append(
            "â•â•â• POJÄ˜CIA TEMATYCZNE (z analizy konkurencji) â•â•â•\n"
            f"NastÄ™pujÄ…ce pojÄ™cia pojawiajÄ… siÄ™ u konkurencji, wpleÄ‡ naturalnie w tekst:\n"
            f"{', '.join(concept_names)}"
            + FLEXION_NOTE
        )
    
    # 4. v50: Co-occurrence pairs: encje ktÃ³re MUSZÄ„ byÄ‡ blisko siebie
    cooc_pairs = pre_batch.get("_cooccurrence_pairs") or []
    if cooc_pairs:
        cooc_lines = []
        for pair in cooc_pairs[:8]:
            if isinstance(pair, dict):
                e1 = pair.get("entity1", pair.get("source", ""))
                e2 = pair.get("entity2", pair.get("target", ""))
                if e1 and e2:
                    cooc_lines.append(f'  â€¢ "{e1}" + "{e2}"  (w tym samym akapicie)')
            elif isinstance(pair, str) and "+" in pair:
                cooc_lines.append(f"  â€¢ {pair}  (w tym samym akapicie)")
        if cooc_lines:
            parts.append(
                "â•â•â• WSPÃ“ÅWYSTÄ˜POWANIE ENCJI (co-occurrence) â•â•â•\n"
                "NastÄ™pujÄ…ce pary encji czÄ™sto pojawiajÄ… siÄ™ RAZEM u konkurencji.\n"
                "UmieÅ›Ä‡ je W TYM SAMYM AKAPICIE , bliskoÅ›Ä‡ buduje kontekst semantyczny:\n"
                + "\n".join(cooc_lines)
            )
    
    # 5. v50: First paragraph entities: encje z pierwszego akapitu top10
    first_para_ents = pre_batch.get("_first_paragraph_entities") or []
    if first_para_ents:
        fp_names = []
        for ent in first_para_ents[:6]:
            name = ent.get("entity", ent.get("text", ent)) if isinstance(ent, dict) else str(ent)
            if name:
                fp_names.append(f'"{name}"')
        if fp_names:
            parts.append(
                "PIERWSZY AKAPIT, encje tematyczne:\n"
                f"WprowadÅº w pierwszym akapicie: {', '.join(fp_names)}.\n"
                "âš ï¸ To POJÄ˜CIA do opisania, NIE ÅºrÃ³dÅ‚a do cytowania. Nie pisz '[encja] podaje/potwierdza...'."
            )
    
    # 6. v50: H2 entities: encje tematyczne do rozmieszczenia w H2
    h2_ents = pre_batch.get("_h2_entities") or []
    if h2_ents:
        h2_names = []
        for ent in h2_ents[:8]:
            name = ent.get("entity", ent.get("text", ent)) if isinstance(ent, dict) else str(ent)
            if name:
                h2_names.append(f'"{name}"')
        if h2_names:
            parts.append(
                "ENCJE TEMATYCZNE W H2:\n"
                f"RozÅ‚Ã³Å¼ w tekÅ›cie: {', '.join(h2_names)}.\n"
                "âš ï¸ To POJÄ˜CIA do opisania, NIE ÅºrÃ³dÅ‚a. Nie pisz '[encja] podaje...'."
            )

    # 7. EAV triples: encja â†’ atrybut â†’ wartoÅ›Ä‡
    # MÃ³wiÄ… modelowi CO NAPISAÄ† o kaÅ¼dej encji â€” konkretny fakt, nie tylko nazwa
    eav_triples = pre_batch.get("_eav_triples") or []
    if eav_triples:
        eav_lines = ["â•â•â• CECHY ENCJI â€” Entity Attribute Value (NAPISZ TE FAKTY) â•â•â•",
                     "Dla kaÅ¼dej poniÅ¼szej encji MUSISZ wyraziÄ‡ podany fakt w tekÅ›cie.",
                     "Nie kopiuj dosÅ‚ownie â€” zbuduj naturalne zdanie zawierajÄ…ce tÄ™ relacjÄ™.",
                     ""]
        primary_eav = [e for e in eav_triples if e.get("is_primary")]
        secondary_eav = [e for e in eav_triples if not e.get("is_primary")]
        if primary_eav:
            e = primary_eav[0]
            eav_lines.append(f'ğŸ¯ GÅÃ“WNA: "{e["entity"]}" â†’ {e["attribute"]} â†’ {e["value"]}')
        for e in secondary_eav[:10]:
            eav_lines.append(f'   â€¢ "{e["entity"]}" ({e.get("type","")}) â†’ {e["attribute"]} â†’ {e["value"]}')
        eav_lines.append("")
        eav_lines.append("âœ… PrzykÅ‚ad zamiany EAV na zdanie:")
        eav_lines.append('   EAV: "kodeks karny â†’ penalizuje â†’ jazdÄ™ po alkoholu art. 178a"')
        eav_lines.append('   ZDANIE: "Art. 178a Kodeksu karnego penalizuje prowadzenie pojazdu w stanie"')
        eav_lines.append('          "nietrzeÅºwoÅ›ci â€” przewiduje karÄ™ do 3 lat pozbawienia wolnoÅ›ci."')
        parts.append("\n".join(eav_lines))

    # 8. SVO triples: podmiot â†’ relacja â†’ obiekt  
    # Gotowe fakty do wbudowania w tekst â€” rdzeÅ„ knowledge graph artykuÅ‚u
    svo_triples = pre_batch.get("_svo_triples") or []
    if svo_triples:
        svo_lines = ["â•â•â• TRÃ“JKI SEMANTYCZNE SVO â€” fakty OBOWIÄ„ZKOWE w artykule â•â•â•",
                     "KaÅ¼da trÃ³jka to fakt ktÃ³ry MUSI znaleÅºÄ‡ siÄ™ gdzieÅ› w artykule.",
                     "MoÅ¼esz rozÅ‚oÅ¼yÄ‡ je na rÃ³Å¼ne sekcje â€” waÅ¼ne Å¼eby byÅ‚y obecne.",
                     ""]
        for i, t in enumerate(svo_triples[:12], 1):
            ctx = f' [{t["context"]}]' if t.get("context") else ""
            svo_lines.append(f'  {i}. {t["subject"]} â†’ {t["verb"]} â†’ {t["object"]}{ctx}')
        svo_lines.append("")
        svo_lines.append("Google Knowledge Graph indeksuje te relacje. Im wiÄ™cej z nich pojawi")
        svo_lines.append("siÄ™ jako wyraÅºne zdania (nie wtrÄ…cenia), tym wyÅ¼szy topic authority.")
        parts.append("\n".join(svo_lines))

    # 9. v57: Entity gaps â€” informational hints, not requirements
    entity_gaps = pre_batch.get("_entity_gaps") or []
    if entity_gaps:
        high_gaps = [g for g in entity_gaps if g.get("priority") == "high"]
        other_gaps = [g for g in entity_gaps if g.get("priority") != "high"]
        gap_lines = [
            "â•â•â• LUKI ENCYJNE (informacja, NIE wymÃ³g) â•â•â•",
            "PoniÅ¼sze encje MOGÄ„ wzbogaciÄ‡ artykuÅ‚, ale NIE MUSISZ ich wszystkich uÅ¼yÄ‡.",
            "Potraktuj je jako inspiracjÄ™ â€” uÅ¼yj tylko tych, ktÃ³re naturalnie pasujÄ… do kontekstu.",
            ""
        ]
        if high_gaps:
            gap_lines.append("Wysoki priorytet (warto rozwaÅ¼yÄ‡):")
            for g in high_gaps[:5]:
                reason = f" â€” {g['why']}" if g.get("why") else ""
                gap_lines.append(f'  ğŸ”´ "{g["entity"]}"{reason}')
        if other_gaps:
            gap_lines.append("Dodatkowe (opcjonalne):")
            for g in other_gaps[:5]:
                gap_lines.append(f'  ğŸŸ¡ "{g["entity"]}"')
        parts.append("\n".join(gap_lines))

    return "\n\n".join(parts) if parts else ""


# _fmt_entities REMOVED v45.4.1 â†’ v50 cleanup: function deleted.
# gpt_instructions_v39 already contains curated "ğŸ§  ENCJE:" section
# (max 3/batch, importanceâ‰¥0.7, with HOW hints). Our version duplicated it
# with dirtier, unfiltered data from S1.

# _fmt_ngrams REMOVED v45.4.1 â†’ v50 cleanup: function deleted.
# Raw statistical n-grams from competitor pages often contain CSS/JS artifacts
# ("button button", "block embed"). Custom GPT produces better text without them.


def _fmt_serp_enrichment(pre_batch):
    serp = pre_batch.get("serp_enrichment") or {}
    enhanced = pre_batch.get("enhanced") or {}

    paa = (serp.get("paa_for_batch") or enhanced.get("paa_from_serp") or [])
    lsi = (serp.get("lsi_keywords") or [])
    chips = serp.get("refinement_chips") or []  # v60: Google search refinement chips

    if not paa and not lsi and not chips:
        return ""

    parts = ["â•â•â• WZBOGACENIE Z SERP â•â•â•"]

    # v60: Refinement chips â€” Google's own topic classification
    if chips:
        chips_str = ", ".join(str(c) for c in chips[:8])
        parts.append(f"Google Refinement Chips (podtematy wg Google): {chips_str}")
        parts.append("â†’ Te podtematy Google uznaje za kluczowe. Upewnij siÄ™, Å¼e artykuÅ‚ pokrywa je.")
        parts.append("")

    if paa:
        parts.append("Pytania ktÃ³re ludzie zadajÄ… w Google (PAA), odpowiedz na 1-2 w tekÅ›cie:")
        for q in paa[:5]:
            q_text = q.get("question", q) if isinstance(q, dict) else q
            if q_text:
                parts.append(f'  â“ {q_text}')

    if lsi:
        lsi_names = [l.get("keyword", l) if isinstance(l, dict) else l for l in lsi[:8]]
        parts.append(f'\nFrazy LSI (bliskoznaczne, wpleÄ‡ naturalnie): {", ".join(lsi_names)}')

    return "\n".join(parts) if len(parts) > 1 else ""


def _fmt_continuation(pre_batch):
    continuation = pre_batch.get("continuation_v39") or {}
    enhanced = pre_batch.get("enhanced") or {}
    cont_ctx = enhanced.get("continuation_context") or {}

    last_h2 = cont_ctx.get("last_h2") or continuation.get("last_h2", "")
    last_ending = cont_ctx.get("last_paragraph_ending") or continuation.get("last_paragraph_ending", "")
    last_topic = cont_ctx.get("last_topic") or continuation.get("last_topic", "")
    transition_hint = continuation.get("transition_hint", "")

    if not last_h2 and not last_ending:
        return ""

    parts = ["â•â•â• KONTYNUACJA â•â•â•",
             "Poprzedni batch zakoÅ„czyÅ‚ siÄ™ na:"]

    if last_h2:
        parts.append(f'  Ostatni H2: "{last_h2}"')
    if last_ending:
        ending_preview = last_ending[:150] + ("..." if len(last_ending) > 150 else "")
        parts.append(f'  Ostatnie zdanie: "{ending_preview}"')
    if last_topic:
        parts.append(f'  Temat: {last_topic}')

    parts.append("\nZacznij PÅYNNIE: nawiÄ…Å¼ do poprzedniego wÄ…tku, ale nie powtarzaj zakoÅ„czenia.")
    if transition_hint:
        parts.append(f'Sugerowane przejÅ›cie: {transition_hint}')

    return "\n".join(parts)


def _fmt_article_memory(article_memory):
    if not article_memory:
        return ""

    parts = ["â•â•â• PAMIÄ˜Ä† ARTYKUÅU (KRYTYCZNE, nie powtarzaj!) â•â•â•"]

    if isinstance(article_memory, dict):
        topics = article_memory.get("topics_covered") or article_memory.get("covered_topics") or []
        if topics:
            parts.append("Sekcje juÅ¼ napisane:")
            for t in topics[:10]:
                if isinstance(t, str):
                    parts.append(f'  âœ“ {t}')
                elif isinstance(t, dict):
                    parts.append(f'  âœ“ {t.get("topic", t.get("h2", ""))}')

        facts = article_memory.get("key_facts_used") or article_memory.get("facts", [])
        # v50.5 FIX 30: Also extract key_points and avoid_repetition from AI memory
        key_points = article_memory.get("key_points") or []
        avoid_rep = article_memory.get("avoid_repetition") or []
        
        all_facts = list(facts) + list(key_points)
        if all_facts:
            parts.append("\nFakty/definicje juÅ¼ podane (NIE POWTARZAJ, odwoÅ‚uj siÄ™: 'wspomniany wczeÅ›niej'):")
            for f in all_facts[:12]:
                parts.append(f'  â€¢ {f}' if isinstance(f, str) else f'  â€¢ {json.dumps(f, ensure_ascii=False)[:100]}')

        if avoid_rep:
            parts.append("\nâ›” TE ZDANIA I FRAZY BYÅY JUÅ» UÅ»YTE â€” NIE POWTARZAJ ICH DOSÅOWNIE:")
            parts.append("   (moÅ¼esz uÅ¼yÄ‡ tego samego SENSU, ale innymi sÅ‚owami)")
            for r in avoid_rep[:8]:
                parts.append(f'  âŒ ZAKAZ: "{r}"')

        phrases_used = article_memory.get("phrases_used") or {}
        if phrases_used:
            high_use = [(k, v) for k, v in phrases_used.items()
                        if isinstance(v, (int, float)) and v >= 3]
            if high_use:
                parts.append("\nFrazy juÅ¼ czÄ™sto uÅ¼yte (ogranicz):")
                for name, count in high_use[:8]:
                    parts.append(f'  â€¢ "{name}" (juÅ¼ {count}Ã—)')
        
        # v50.5 FIX 30: Add strong anti-repetition instruction
        if topics and len(topics) >= 2:
            parts.append(
                "\nâš ï¸ ZASADA ANTY-POWTÃ“RZEÅƒ: JeÅ›li pojÄ™cie (np. prawo Ohma, definicja ampera) "
                "zostaÅ‚o ZDEFINIOWANE w poprzedniej sekcji, NIE definiuj go ponownie. "
                "Zamiast tego: uÅ¼yj go w nowym kontekÅ›cie lub odnieÅ› siÄ™ krÃ³tko: "
                "'zgodnie z omÃ³wionym wczeÅ›niej prawem Ohma'. "
                "PowtÃ³rzenie definicji = utrata punktÃ³w jakoÅ›ci."
            )
    elif isinstance(article_memory, str):
        parts.append(_word_trim(article_memory, 1500))

    return "\n".join(parts) if len(parts) > 1 else ""


def _fmt_coverage_density(pre_batch):
    coverage = pre_batch.get("coverage") or {}
    density = pre_batch.get("density") or {}
    main_kw = pre_batch.get("main_keyword") or {}
    keyword_tracking = pre_batch.get("keyword_tracking") or {}

    if not coverage and not density and not main_kw:
        return ""

    parts = ["â•â•â• STATUS POKRYCIA FRAZ â•â•â•"]

    if main_kw:
        kw_name = main_kw.get("keyword", "") if isinstance(main_kw, dict) else str(main_kw)
        synonyms = main_kw.get("synonyms", []) if isinstance(main_kw, dict) else []
        if kw_name:
            parts.append(f'HasÅ‚o gÅ‚Ã³wne: "{kw_name}"')
        if synonyms:
            parts.append(f'Synonimy (uÅ¼ywaj zamiennie): {", ".join(synonyms[:5])}')

    current_cov = coverage.get("current", coverage.get("current_coverage"))
    target_cov = coverage.get("target", coverage.get("target_coverage"))
    if current_cov is not None and target_cov is not None:
        parts.append(f'\nPokrycie fraz: {current_cov}% z docelowych {target_cov}%')

    missing = coverage.get("missing_phrases") or coverage.get("uncovered") or []
    if missing:
        parts.append("âš ï¸ BRAKUJÄ„CE FRAZY, wpleÄ‡ w tym batchu:")
        for m in missing[:8]:
            name = m.get("keyword", m) if isinstance(m, dict) else m
            parts.append(f'  â†’ "{name}"')

    if density:
        current_d = density.get("current")
        target_range = density.get("target_range") or []
        if current_d is not None:
            range_str = f'{target_range[0]}-{target_range[1]}%' if len(target_range) >= 2 else "1.5-2.5%"
            status = "âœ… w normie" if target_range and len(target_range) >= 2 and target_range[0] <= current_d <= target_range[1] else "âš ï¸ do korekty"
            parts.append(f'\nGÄ™stoÅ›Ä‡ fraz: {current_d}% (cel: {range_str}) {status}')

        overused_d = density.get("overused") or []
        if overused_d:
            over_names = ", ".join(f'"{o}"' if isinstance(o, str) else f'"{o.get("keyword", "")}"' for o in overused_d[:5])
            parts.append(f'NaduÅ¼ywane: {over_names}, uÅ¼yj synonimÃ³w')

    if keyword_tracking:
        total_kw = keyword_tracking.get("total_keywords", 0)
        covered_kw = keyword_tracking.get("covered", 0)
        if total_kw and covered_kw:
            parts.append(f'\nTracking: {covered_kw}/{total_kw} fraz pokrytych')

    return "\n".join(parts) if len(parts) > 1 else ""


def _fmt_style(pre_batch):
    style = pre_batch.get("style_instructions") or pre_batch.get("style_instructions_v39") or {}

    if not style:
        return ""

    parts = ["â•â•â• STYL â•â•â•"]

    if isinstance(style, dict):
        tone = style.get("tone", "")
        if tone:
            parts.append(f'Ton: {tone}')

        para_len = style.get("paragraph_length", "")
        if para_len:
            parts.append(f'DÅ‚ugoÅ›Ä‡ akapitÃ³w: {para_len} sÅ‚Ã³w')

        forbidden = style.get("forbidden_phrases") or style.get("avoid_phrases") or []
        if forbidden:
            parts.append(f'ZAKAZANE zwroty: {", ".join(f"{f}" for f in forbidden[:8])}')

        preferred = style.get("preferred_phrases") or style.get("use_phrases") or []
        if preferred:
            parts.append(f'Preferowane zwroty: {", ".join(preferred[:5])}')

        persona = style.get("persona", "")
        if persona:
            parts.append(f'Perspektywa: {persona}')
    elif isinstance(style, str):
        parts.append(_word_trim(style, 500))

    return "\n".join(parts) if len(parts) > 1 else ""


def _fmt_legal_medical(pre_batch):
    legal_ctx = pre_batch.get("legal_context") or {}
    medical_ctx = pre_batch.get("medical_context") or {}
    ymyl_enrich = pre_batch.get("_ymyl_enrichment") or {}
    ymyl_intensity = pre_batch.get("_ymyl_intensity", "full")

    parts = []

    # v50: For "light" YMYL: DON'T inject full legal/medical framework
    if ymyl_intensity == "light":
        light_note = pre_batch.get("_light_ymyl_note", "")
        if light_note:
            parts.append("â•â•â• ASPEKT REGULACYJNY (peryferyjny, NIE gÅ‚Ã³wny temat!) â•â•â•")
            parts.append(f"  {light_note}")
            parts.append("  âš ï¸ OGRANICZENIE: Wspomnij o regulacjach MAX 1-2 razy w CAÅYM artykule.")
            parts.append("  NIE cytuj artykuÅ‚Ã³w ustaw, NIE dodawaj sygnatur orzeczeÅ„,")
            parts.append("  NIE dodawaj disclaimera o konsultacji z prawnikiem/lekarzem.")
            parts.append("  ArtykuÅ‚ jest EDUKACYJNY/TECHNICZNY, nie prawniczy/medyczny.")
        return "\n".join(parts) if parts else ""

    if legal_ctx and legal_ctx.get("active"):
        parts.append("â•â•â• KONTEKST PRAWNY (YMYL) â•â•â•")
        parts.append("Ten artykuÅ‚ dotyczy tematyki prawnej. MUSISZ:")
        parts.append("  1. CytowaÄ‡ realne przepisy i orzeczenia â€” ALE TYLKO te pasujÄ…ce do gaÅ‚Ä™zi prawa artykuÅ‚u")
        parts.append("  2. DodaÄ‡ disclaimer o konsultacji z prawnikiem")
        parts.append("  3. NIE wymyÅ›laÄ‡ sygnatur ani dat orzeczeÅ„")
        parts.append("")
        parts.append("ğŸš« BÅÄ˜DY KRYTYCZNE â€” BEZWZGLÄ˜DNY ZAKAZ:")
        parts.append("  â€¢ JEDNOSTKI: mg/100 ml â†’ BÅÄ„D. UÅ¼ywaj: promile (â€°) lub mg/dmÂ³")
        parts.append("  â€¢ KARA 178a Â§1: do 2 lat â†’ BÅÄ„D. PrawidÅ‚owo: do 3 lat (nowelizacja 2023)")
        parts.append("  â€¢ RECYDYWA: nie definiuj terminem '2 lat' â€” brak takiego wymogu")
        parts.append("  â€¢ SYGNATURA I C / II C w kontekÅ›cie konfiskaty â†’ BÅÄ„D: to sprawa cywilna")
        parts.append("  â€¢ PLACEHOLDER 'odpowiednich przepisÃ³w' â†’ zawsze podaj konkretny art.")
        
        # Inject Wikipedia articles if available
        wiki_arts = pre_batch.get("legal_wiki_articles") or []
        if wiki_arts:
            parts.append("")
            parts.append("WIKIPEDIA â€” TREÅšÄ† PRZEPISÃ“W (moÅ¼esz cytowaÄ‡ jako ÅºrÃ³dÅ‚o uzupeÅ‚niajÄ…ce):")
            for w in wiki_arts[:4]:
                if w.get("found"):
                    parts.append(f"  [{w['article_ref']}] {w['title']}:")
                    parts.append(f"  {w['extract'][:300]}")
                    parts.append(f"  Å¹rÃ³dÅ‚o: {w['url']}")
                    parts.append("")
        parts.append("")
        parts.append("âš ï¸ WERYFIKACJA ORZECZEÅƒ â€” OBOWIÄ„ZKOWA:")
        parts.append("  Sygnatura zdradza typ sprawy:")
        parts.append("  â€¢ II K, III K, AKa, AKo, AKz = KARNA â€” pasuje do art. KK, KW")
        parts.append("  â€¢ I C, II C, ACa, ACo = CYWILNA â€” pasuje do art. KC, KRO")
        parts.append("  â€¢ I P, II P, Pa = PRACY â€” pasuje do KP")
        parts.append("  âŒ NIE cytuj wyroku cywilnego (I C, II C) w artykule o prawie KARNYM")
        parts.append("  âŒ NIE cytuj wyroku karnego (II K) w artykule o prawie CYWILNYM")
        parts.append("  JeÅ›li Å¼aden z podanych wyrokÃ³w nie pasuje do gaÅ‚Ä™zi prawa â€” pomiÅ„ cytowania,")
        parts.append("  napisz artykuÅ‚ bez sygnatur. Lepiej brak cytatu niÅ¼ bÅ‚Ä™dny.")
        
        # v47.2: Claude's enrichment: specific articles and concepts
        legal_enrich = ymyl_enrich.get("legal", {})
        if legal_enrich.get("articles"):
            parts.append("")
            parts.append("PODSTAWA PRAWNA (kluczowe przepisy):")
            for art in legal_enrich["articles"][:5]:
                parts.append(f"  â€¢ {art}")
        if legal_enrich.get("acts"):
            parts.append(f"  Ustawy: {', '.join(legal_enrich['acts'][:4])}")
        if legal_enrich.get("key_concepts"):
            parts.append(f"  Kluczowe pojÄ™cia: {', '.join(legal_enrich['key_concepts'][:6])}")
        
        parts.append("")
        parts.append("FORMATY CYTOWAÅƒ PRAWNYCH:")
        parts.append('  â€¢ Przepisy: "art. 13 Â§ 1 k.c.", "art. 58 Â§ 2 k.r.o."')
        parts.append('  â€¢ Wyroki: "wyrok SN z 12.03.2021, III CZP 45/19"')
        parts.append('  â€¢ Dziennik Ustaw: "Dz.U. 2023 poz. 1234"')
        parts.append('  Causal legal: "niedopeÅ‚nienie obowiÄ…zku skutkuje...", "brak zgÅ‚oszenia prowadzi do..."')

        instruction = legal_ctx.get("legal_instruction", "")
        if instruction:
            parts.append(f'\n{instruction[:600]}')

        judgments = legal_ctx.get("top_judgments") or []
        if judgments:
            parts.append("\nOrzeczenia do zacytowania:")
            for j in judgments[:3]:
                if isinstance(j, dict):
                    sig = j.get("signature", j.get("caseNumber", ""))
                    court = j.get("court", j.get("courtName", ""))
                    date = j.get("date", j.get("judgmentDate", ""))
                    matched = j.get("matched_article", "")
                    line = f'  â€¢ {sig}, {court} ({date})'
                    if matched:
                        line += f' [dot. {matched}]'
                    parts.append(line)

        citation_hint = legal_ctx.get("citation_hint", "")
        if citation_hint:
            parts.append(f'\n{citation_hint}')

    if medical_ctx and medical_ctx.get("active"):
        if parts:
            parts.append("")
        parts.append("â•â•â• KONTEKST MEDYCZNY (YMYL) â•â•â•")
        parts.append("Ten artykuÅ‚ dotyczy tematyki zdrowotnej. MUSISZ:")
        parts.append("  1. CytowaÄ‡ ÅºrÃ³dÅ‚a naukowe (podane niÅ¼ej)")
        parts.append("  2. NIE wymyÅ›laÄ‡ statystyk ani nazw badaÅ„")
        parts.append("  3. DodaÄ‡ informacjÄ™ o konsultacji z lekarzem")
        
        # v47.2: Claude's enrichment: specialization, evidence guidelines
        med_enrich = ymyl_enrich.get("medical", {})
        if med_enrich.get("specialization"):
            parts.append(f"\n  Specjalizacja: {med_enrich['specialization']}")
        if med_enrich.get("condition"):
            cond = med_enrich["condition"]
            latin = med_enrich.get("condition_latin", "")
            icd = med_enrich.get("icd10", "")
            parts.append(f"  Choroba/stan: {cond}" + (f" ({latin})" if latin else "") + (f" [ICD-10: {icd}]" if icd else ""))
        if med_enrich.get("key_drugs"):
            parts.append(f"  Kluczowe leki: {', '.join(med_enrich['key_drugs'][:5])}")
        if med_enrich.get("evidence_note"):
            parts.append(f"\n  âš ï¸ WYTYCZNE: {med_enrich['evidence_note']}")
        
        parts.append("")
        parts.append("FORMATY CYTOWAÅƒ MEDYCZNYCH:")
        parts.append('  â€¢ "Smith i wsp. (2023)", "Kowalski et al. (2024)"')
        parts.append('  â€¢ "PMID:12345678", "DOI:10.1000/xyz"')
        parts.append("")
        parts.append("HIERARCHIA DOWODÃ“W (cytuj najwyÅ¼szy dostÄ™pny):")
        parts.append("  1. Meta-analiza / PrzeglÄ…d systematyczny (najsilniejszy)")
        parts.append("  2. RCT (badanie randomizowane)")
        parts.append("  3. Badanie kohortowe")
        parts.append("  4. Opis przypadku")
        parts.append("  5. Opinia eksperta (najsÅ‚abszy)")
        parts.append('  Causal medical: "nieleczone prowadzi do...", "brak terapii skutkuje..."')

        instruction = medical_ctx.get("medical_instruction", "")
        if instruction:
            parts.append(f'\n{instruction[:600]}')

        publications = medical_ctx.get("top_publications") or []
        if publications:
            parts.append("\nPublikacje do zacytowania:")
            for p in publications[:5]:
                if isinstance(p, dict):
                    title = p.get("title", "")[:80]
                    authors = p.get("authors", "")[:40]
                    year = p.get("year", "")
                    pmid = p.get("pmid", "")
                    parts.append(f'  â€¢ {authors} ({year}): "{title}" PMID:{pmid}')

    return "\n".join(parts) if parts else ""


def _fmt_experience_markers(pre_batch):
    enhanced = pre_batch.get("enhanced") or {}
    markers = enhanced.get("experience_markers") or []

    if not markers:
        return ""

    parts = ["â•â•â• SYGNAÅY DOÅšWIADCZENIA (E-E-A-T) â•â•â•",
             "WpleÄ‡ min 1 sygnaÅ‚, Å¼e autor MA doÅ›wiadczenie z tematem:"]

    for m in markers[:5]:
        if isinstance(m, str):
            parts.append(f'  â€¢ {m}')
        elif isinstance(m, dict):
            parts.append(f'  â€¢ {m.get("marker", m.get("text", ""))}')

    return "\n".join(parts)


def _fmt_causal_context(pre_batch):
    enhanced = pre_batch.get("enhanced") or {}
    causal = enhanced.get("causal_context", "")
    info_gain = enhanced.get("information_gain", "")

    parts = []

    if causal:
        parts.append("â•â•â• KONTEKST PRZYCZYNOWO-SKUTKOWY â•â•â•")
        parts.append(_word_trim(causal, 500))

    if info_gain:
        if parts:
            parts.append("")
        parts.append("â•â•â• INFORMATION GAIN (przewaga nad konkurencjÄ…) â•â•â•")
        parts.append(_word_trim(info_gain, 500))

    return "\n".join(parts) if parts else ""


def _fmt_depth_signals(pre_batch):
    """Depth signals: inject when previous batch scored low on depth
    or always for FULL YMYL content.
    
    v50: Only force for full YMYL intensity, not light.
    Based on 10 depth signals from GPT prompt with weights.
    """
    last_depth = pre_batch.get("_last_depth_score")
    is_ymyl = pre_batch.get("_is_ymyl", False)
    ymyl_intensity = pre_batch.get("_ymyl_intensity", "none")
    is_full_ymyl = is_ymyl and ymyl_intensity == "full"
    
    # Only force depth for FULL YMYL, not light
    threshold = 40 if is_full_ymyl else 30
    if last_depth is not None and last_depth >= threshold and not is_full_ymyl:
        return ""
    
    # If no depth data at all and not full YMYL, skip
    if last_depth is None and not is_full_ymyl:
        return ""
    
    parts = ["â•â•â• SYGNAÅY GÅÄ˜BOKOÅšCI (dodaj od najwyÅ¼szej wagi) â•â•â•"]
    
    if last_depth is not None:
        parts.append(f"âš ï¸ Ostatni batch: depth {last_depth}/100 (prÃ³g: {threshold}). Dodaj wiÄ™cej konkretÃ³w!")
    
    parts.append("")
    # v50: Legal references only for FULL YMYL
    if is_full_ymyl:
        parts.append("WAGA 2.5: referencje prawne (art. k.c., wyroki SN, Dz.U.) + naukowe (PMID, DOI, badania)")
    parts.append('WAGA 2.0: konkretne liczby (kwoty PLN, %, okresy, NIE "okoÅ‚o")')
    parts.append('WAGA 1.8: nazwane instytucje (konkretny sÄ…d/urzÄ…d, NIE "wÅ‚aÅ›ciwy sÄ…d") + praktyczne porady (w praktyce, czÄ™sty bÅ‚Ä…d)')
    parts.append("WAGA 1.5: wyjaÅ›nienia przyczynowe (poniewaÅ¼, w wyniku) + wyjÄ…tki (z wyjÄ…tkiem, chyba Å¼e) + konkretne daty")
    parts.append("WAGA 1.2: porÃ³wnania (w odrÃ³Å¼nieniu od) | WAGA 1.0: kroki procedur (najpierw/nastÄ™pnie)")
    
    return "\n".join(parts)


def _fmt_natural_polish(pre_batch):
    """v50: Natural Polish writing instructions: fleksja, spacing, anti-stuffing.

    Based on natural_polish_instructions.py (master-seo-api-main).
    Inlined here because prompt_builder runs in Brajn, not master.
    
    Prevents keyword stuffing by teaching Claude that:
    1. Polish inflected forms count as the same keyword
    2. Minimum spacing between repetitions is required
    3. Max 2 uses of same phrase per paragraph
    """
    # Get keywords from pre_batch
    keywords_info = pre_batch.get("keywords") or {}
    must_kw = keywords_info.get("basic_must_use") or []
    ext_kw = keywords_info.get("extended_this_batch") or []

    all_kw = []
    for kw in must_kw + ext_kw:
        if isinstance(kw, dict):
            name = kw.get("keyword", "")
            kw_type = kw.get("type", "BASIC").upper()
        elif isinstance(kw, str):
            name = kw
            kw_type = "BASIC"
        else:
            continue
        if name:
            all_kw.append((name, kw_type))

    if not all_kw:
        return ""

    # Spacing rules
    SPACING = {"MAIN": 60, "BASIC": 80, "EXTENDED": 120}

    parts = ["â•â•â• NATURALNY POLSKI, ANTY-STUFFING â•â•â•"]

    parts.append(
        "ğŸ”„ FLEKSJA: Odmiany frazy liczÄ… siÄ™ jako jedno uÅ¼ycie!\n"
        '   "zespÃ³Å‚ turnera" = "zespoÅ‚u turnera" = "zespoÅ‚em turnera"\n'
        "   Pisz naturalnie, uÅ¼ywaj rÃ³Å¼nych przypadkÃ³w gramatycznych.\n"
        "   NIE MUSISZ powtarzaÄ‡ frazy w mianowniku. System zaliczy kaÅ¼dÄ… odmianÄ™."
    )

    spacing_lines = []
    for name, kw_type in all_kw[:8]:
        spacing = SPACING.get(kw_type, 80)
        spacing_lines.append(f'  â€¢ "{name}" ({kw_type}): min {spacing} sÅ‚Ã³w miÄ™dzy powtÃ³rzeniami')
    if spacing_lines:
        parts.append("ğŸ“ ODSTÄ˜PY MIÄ˜DZY POWTÃ“RZENIAMI:\n" + "\n".join(spacing_lines))

    # Dynamiczny zakaz anaphor dla encji gÅ‚Ã³wnej
    _raw_main = pre_batch.get("main_keyword") or {}
    _main_name = _raw_main.get("keyword", "") if isinstance(_raw_main, dict) else str(_raw_main)
    if _main_name:
        # Wczytaj synonimy z topical entity generator (zapisane w entity_seo)
        _entity_seo = (pre_batch.get("s1_data") or {}).get("entity_seo") or pre_batch.get("entity_seo") or {}
        _dynamic_synonyms = _entity_seo.get("entity_synonyms", [])
        if _dynamic_synonyms and len(_dynamic_synonyms) >= 2:
            synonyms = ", ".join(str(s) for s in _dynamic_synonyms[:7])
        else:
            # Fallback: encje MUST-MENTION jako zamienniki podmiotowe
            _must = _entity_seo.get("must_mention_entities", [])
            _must_names = [str(e.get("entity", e) if isinstance(e, dict) else e) for e in _must[:4]]
            _must_names = [n for n in _must_names if n and n.lower() != _main_name.lower()]
            if _must_names:
                synonyms = ", ".join(_must_names[:4]) + ", ta kwestia, ten aspekt"
            else:
                synonyms = "ta kwestia, ten problem, omawiany aspekt, ta sytuacja"
        parts.append("ANTY-ANAPHORA [" + _main_name + "] MAX 2 ZDANIA Z RZEDU.\nPrzy 3. zdaniu zmien podmiot na: " + synonyms)

    # Multi-entity synonyms: mapa zamiennikÃ³w dla wielu encji
    _multi_syns = _entity_seo.get("multi_entity_synonyms", {}) if _main_name else {}
    if _multi_syns:
        syn_lines = []
        for ent, syns in list(_multi_syns.items())[:5]:
            syn_lines.append(f'  "{ent}" â†’ {", ".join(syns[:3])}')
        parts.append(
            "ğŸ“– MAPA SYNONIMÃ“W (uÅ¼ywaj zamiast powtÃ³rzeÅ„):\n" + "\n".join(syn_lines)
        )

    parts.append(
        "âš ï¸ ZASADY:\n"
        "  â€¢ Max 2Ã— ta sama fraza w jednym akapicie\n"
        "  â€¢ RozkÅ‚adaj frazy RÃ“WNOMIERNIE w tekÅ›cie (nie grupuj na poczÄ…tku/koÅ„cu)\n"
        "  â€¢ Zamiast powtÃ³rzenia uÅ¼yj: synonimu, zaimka, opisu ('ta choroba', 'omawiany zespÃ³Å‚')\n"
        "  â€¢ Podmiot â†’ dopeÅ‚nienie â†’ synonim â†’ kolejny akapit â†’ ponownie fraza"
    )

    # Fix #64 Layer 3 â€” dodatkowe reguÅ‚y anafory globalnej (FAQ + zero-subject + zaimek 'To')
    parts.append(
        "ğŸ”„ ANTY-ANAPHORA GLOBALNA:\n"
        "  â€¢ FAQ/sekcja pytaÅ„: kaÅ¼de pytanie MUSI zaczynaÄ‡ siÄ™ INNYM sÅ‚owem.\n"
        "    Rotuj: 'Czy', 'Kiedy', 'Jak', 'Co zrobiÄ‡ gdy', 'Ile', 'Dlaczego', 'W jakich', 'Od kiedy'.\n"
        "    NIE pisz 4+ pytaÅ„ z rzÄ™du zaczynajÄ…cych siÄ™ od tego samego sÅ‚owa.\n"
        "  â€¢ NIE zaczynaj zdania od imiesÅ‚owu bez podmiotu:\n"
        "    Å¹LE: 'ZlekcewaÅ¼one prowadzÄ… do...' / 'Nieleczone skutkujÄ…...'\n"
        "    DOBRZE: 'Nieleczone objawy prowadzÄ… do...' / 'ZlekcewaÅ¼one symptomy skutkujÄ…...'\n"
        "  â€¢ NIE uÅ¼ywaj 'To' jako podmiotu zdania:\n"
        "    Å¹LE: 'To klucz do...' / 'To podstawa...' / 'To pierwszy krok...'\n"
        "    DOBRZE: 'Badanie sÅ‚uchu stanowi klucz do...' / 'WÅ‚aÅ›ciwa diagnoza to podstawa...'"
    )

    # v57: Anti-stuffing naturalness check + anti-geographic stuffing
    parts.append(
        "ğŸš« NATURALNOÅšÄ† â€” TEST CZYTELNIKA:\n"
        "  Przed uÅ¼yciem frazy kluczowej zadaj sobie pytanie:\n"
        "  'Czy ekspert powiedziaÅ‚by to w rozmowie, czy tylko pisze siÄ™ to pod SEO?'\n"
        "  âŒ STUFFING: 'Detektyw Warszawa obsÅ‚uguje w wojewÃ³dztwie mazowieckim.' (Warszawa zbÄ™dne)\n"
        "  âŒ STUFFING: 'Witaminy na skÃ³rÄ™ to temat o witaminach na skÃ³rÄ™.' (tautologia)\n"
        "  âŒ STUFFING: 'Bariera lipidowa skÃ³ry chroni barierÄ™ lipidowÄ….' (powtÃ³rzenie bez treÅ›ci)\n"
        "  âœ… NATURALNIE: 'Bariera lipidowa chroni naskÃ³rek przed utratÄ… wody.' (fakt + funkcja)\n"
        "  âœ… NATURALNIE: 'Ceramidy odbudowujÄ… strukturÄ™ bariery ochronnej skÃ³ry.' (synonim + mechanizm)\n"
        "\n"
        "  REGUÅA: JeÅ›li usuniÄ™cie frazy kluczowej NIE zmienia sensu zdania = stuffing.\n"
        "  KaÅ¼de uÅ¼ycie frazy musi WNOSIÄ† informacjÄ™, nie tylko 'karmiÄ‡ algorytm'."
    )

    return "\n".join(parts)


def _fmt_phrase_hierarchy(pre_batch):
    """Format phrase hierarchy: roots, extensions, strategy.
    
    Data sources (checked in order):
    1. pre_batch["enhanced"]["phrase_hierarchy"]: from enhanced_pre_batch.py
    2. pre_batch["_phrase_hierarchy"]: injected by app.py from /phrase_hierarchy endpoint
    """
    hier = (pre_batch.get("enhanced") or {}).get("phrase_hierarchy") or pre_batch.get("_phrase_hierarchy") or {}
    if not hier:
        return ""

    parts = ["â•â•â• WAÅ»NOÅšÄ† FRAZ (ktÃ³re obowiÄ…zkowe, ktÃ³re opcjonalne) â•â•â•"]

    strategies = hier.get("strategies") or {}

    # 1. Extensions sufficient: don't repeat root standalone
    ext_suff = strategies.get("extensions_sufficient") or {}
    ext_roots = ext_suff.get("roots") or []
    if ext_roots:
        parts.append("RDZENIE POKRYTE ROZSZERZENIAMI (NIE powtarzaj samodzielnie!):")
        for root_info in ext_roots[:8]:
            if isinstance(root_info, dict):
                root = root_info.get("root", root_info.get("keyword", ""))
                extensions = root_info.get("extensions", [])
                ext_list = ", ".join(f'"{e}"' if isinstance(e, str) else f'"{e.get("keyword", "")}"' for e in extensions[:5])
                parts.append(f'  â€¢ "{root}" â†’ uÅ¼ywaj rozszerzeÅ„: {ext_list}')
            elif isinstance(root_info, str):
                parts.append(f'  â€¢ "{root_info}" â†’ uÅ¼ywaj rozszerzeÅ„ zamiast rdzenia')

    # 2. Mixed: some standalone + extensions
    mixed = strategies.get("mixed") or {}
    mixed_roots = mixed.get("roots") or []
    if mixed_roots:
        parts.append("RDZENIE MIESZANE (kilka samodzielnych uÅ¼yÄ‡ + rozszerzenia):")
        for root_info in mixed_roots[:8]:
            if isinstance(root_info, dict):
                root = root_info.get("root", root_info.get("keyword", ""))
                standalone = root_info.get("standalone_uses", "1-2")
                extensions = root_info.get("extensions", [])
                ext_list = ", ".join(f'"{e}"' if isinstance(e, str) else f'"{e.get("keyword", "")}"' for e in extensions[:5])
                parts.append(f'  â€¢ "{root}" â†’ {standalone}Ã— samodzielnie + rozszerzenia: {ext_list}')
            elif isinstance(root_info, str):
                parts.append(f'  â€¢ "{root_info}" â†’ kilka samodzielnie + rozszerzenia')

    # 3. Need standalone: extensions insufficient
    standalone = strategies.get("need_standalone") or {}
    standalone_roots = standalone.get("roots") or []
    if standalone_roots:
        parts.append("RDZENIE WYMAGAJÄ„CE SAMODZIELNYCH UÅ»YÄ†:")
        for root_info in standalone_roots[:8]:
            if isinstance(root_info, dict):
                root = root_info.get("root", root_info.get("keyword", ""))
                target = root_info.get("remaining", root_info.get("target", "?"))
                parts.append(f'  â€¢ "{root}" â†’ uÅ¼yj samodzielnie jeszcze ~{target}Ã—')
            elif isinstance(root_info, str):
                parts.append(f'  â€¢ "{root_info}" â†’ uÅ¼yj samodzielnie')

    # 4. Entity phrases (if available)
    entity_phrases = hier.get("entity_phrases") or []
    if entity_phrases:
        ep_list = ", ".join(f'"{e}"' if isinstance(e, str) else f'"{e.get("keyword", "")}"' for e in entity_phrases[:6])
        parts.append(f"FRAZY ENCYJNE (wpleÄ‡ naturalnie): {ep_list}")

    # 5. Triplet phrases (if available)
    triplet_phrases = hier.get("triplet_phrases") or []
    if triplet_phrases:
        tp_list = ", ".join(f'"{t}"' if isinstance(t, str) else f'"{t.get("keyword", "")}"' for t in triplet_phrases[:6])
        parts.append(f"FRAZY TRIPLETOWE (relacje do wplecenia): {tp_list}")

    if len(parts) <= 1:
        return ""

    return "\n".join(parts)


def _fmt_h2_remaining(pre_batch):
    h2_remaining = pre_batch.get("h2_remaining") or []
    if not h2_remaining:
        return ""

    h2_list = ", ".join(f'"{h}"' for h in h2_remaining[:6])
    return f"â•â•â• PLAN â•â•â•\nPozostaÅ‚e sekcje H2 w artykule: {h2_list}\nNie zachodÅº na ich tematy. ZostanÄ… pokryte pÃ³Åºniej."


def _fmt_output_format(h2, batch_type):
    if batch_type in ("INTRO", "intro"):
        return f"""â•â•â• FORMAT ODPOWIEDZI â•â•â•
Pisz TYLKO treÅ›Ä‡ leadu (wstÄ™pu). NIE zaczynaj od "h2:". Lead nie ma nagÅ‚Ã³wka.
120-200 sÅ‚Ã³w w 3 krÃ³tkich akapitach (odpowiedÅº â†’ kontekst â†’ zachÄ™ta).
FrazÄ™ gÅ‚Ã³wnÄ… wpleÄ‡ w PIERWSZE zdanie. KaÅ¼dy akapit: 2-4 zdaÅ„.
NIE dodawaj komentarzy, wyjaÅ›nieÅ„, meta-tekstu. TYLKO treÅ›Ä‡ leadu."""
    
    return f"""â•â•â• FORMAT ODPOWIEDZI â•â•â•
Pisz TYLKO treÅ›Ä‡ tego batcha. Zaczynaj dokÅ‚adnie od:

h2: {h2}

Potem: akapity tekstu (40-150 sÅ‚Ã³w kaÅ¼dy), opcjonalnie h3: [podsekcja].

ÅšCIANA TEKSTU = UTRATA CZYTELNIKA:
  â€¢ Akapit NIGDY nie powinien przekraczaÄ‡ 4-5 zdaÅ„ (~80 sÅ‚Ã³w).
  â€¢ Gdy opisujesz 3+ elementÃ³w, krokÃ³w lub cech â†’ UÅ»YJ LISTY HTML (<ul>/<ol>).
  â€¢ Gdy porÃ³wnujesz opcje â†’ rozwaÅ¼ krÃ³tkÄ… tabelÄ™ lub listÄ™.
  â€¢ MiÄ™dzy akapitami: przeplataj treÅ›Ä‡ z listami/punktami.
  Cel: kaÅ¼da sekcja H2 zawiera MIN 1 listÄ™ punktowÄ… lub numerowanÄ….

NIE dodawaj komentarzy, wyjaÅ›nieÅ„, podsumowaÅ„. TYLKO treÅ›Ä‡ artykuÅ‚u."""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FAQ PROMPT BUILDER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_faq_system_prompt(pre_batch=None):
    """System prompt for FAQ generation."""
    base = (
        "JesteÅ› doÅ›wiadczonym polskim copywriterem SEO. "
        "Piszesz sekcjÄ™ FAQ: zwiÄ™zÅ‚e, konkretne odpowiedzi na pytania uÅ¼ytkownikÃ³w. "
        "KaÅ¼da odpowiedÅº ma szansÄ™ trafiÄ‡ do Google Featured Snippet. Pisz bezpoÅ›rednio i merytorycznie."
    )

    gpt_instructions = ""
    if pre_batch:
        gpt_instructions = pre_batch.get("gpt_instructions_v39", "")

    if gpt_instructions:
        return base + "\n\n" + gpt_instructions
    return base


def build_faq_user_prompt(paa_data, pre_batch=None):
    """User prompt for FAQ generation."""
    # Normalize: if paa_data is a list (raw PAA questions), wrap it
    if isinstance(paa_data, list):
        paa_data = {"serp_paa": paa_data}
    elif not isinstance(paa_data, dict):
        paa_data = {}
    paa_questions = paa_data.get("serp_paa") or []
    unused = paa_data.get("unused_keywords") or {}
    avoid = paa_data.get("avoid_in_faq") or []
    if isinstance(avoid, dict):
        avoid = avoid.get("topics") or []
    elif isinstance(avoid, str):
        avoid = [avoid] if avoid.strip() else []
    elif not isinstance(avoid, list):
        avoid = []
    instructions_raw = paa_data.get("instructions", "")
    if isinstance(instructions_raw, dict):
        parts = []
        for k, v in instructions_raw.items():
            if isinstance(v, str):
                parts.append(f"â€¢ {v}")
            elif isinstance(v, dict):
                for sk, sv in v.items():
                    if isinstance(sv, str):
                        parts.append(f"â€¢ {sk}: {sv}")
        instructions = "\n".join(parts)
    elif isinstance(instructions_raw, str):
        instructions = instructions_raw
    else:
        instructions = ""

    enhanced_paa = []
    if pre_batch:
        enhanced = pre_batch.get("enhanced") or {}
        if not isinstance(enhanced, dict):
            enhanced = {}
        enhanced_paa = enhanced.get("paa_from_serp") or []
        if not isinstance(enhanced_paa, list):
            enhanced_paa = []

    keyword_limits = {}
    if pre_batch:
        keyword_limits = pre_batch.get("keyword_limits") or {}
        if not isinstance(keyword_limits, dict):
            keyword_limits = {}
    stop_raw = keyword_limits.get("stop_keywords") or []
    stop_names = [s.get("keyword", s) if isinstance(s, dict) else s for s in stop_raw]

    style = {}
    if pre_batch:
        style = pre_batch.get("style_instructions") or {}

    sections = []

    sections.append("""â•â•â• SEKCJA FAQ â•â•â•
Napisz sekcjÄ™ FAQ. Zaczynaj DOKÅADNIE od:
h2: NajczÄ™Å›ciej zadawane pytania""")

    all_paa = list(dict.fromkeys(paa_questions + enhanced_paa))
    if all_paa:
        sections.append("Pytania z Google (People Also Ask), to NAPRAWDÄ˜ pytajÄ… uÅ¼ytkownicy:")
        for i, q in enumerate(all_paa[:8], 1):
            q_text = q.get("question", q) if isinstance(q, dict) else q
            if q_text and q_text.strip():
                sections.append(f'  {i}. {q_text}')
        sections.append("Wybierz 4-6 najlepszych. MoÅ¼esz przeformuÅ‚owaÄ‡, ale zachowaj sens.")

    if unused:
        if isinstance(unused, dict):
            unused_list = []
            for cat, items in unused.items():
                if isinstance(items, list):
                    unused_list.extend(items[:5])
                elif isinstance(items, str):
                    unused_list.append(items)
            if unused_list:
                names = ", ".join(f'"{u}"' if isinstance(u, str) else f'"{u.get("keyword", "")}"' for u in unused_list[:8])
                sections.append(f'\nFrazy jeszcze nieuÅ¼yte, wpleÄ‡ w odpowiedzi: {names}')
        elif isinstance(unused, list):
            names = ", ".join(f'"{u}"' for u in unused[:8])
            sections.append(f'\nFrazy jeszcze nieuÅ¼yte, wpleÄ‡ w odpowiedzi: {names}')

    if avoid:
        topics = ", ".join(f'"{a}"' if isinstance(a, str) else f'"{a.get("topic", "")}"' for a in avoid[:8])
        sections.append(f'\nNIE powtarzaj tematÃ³w juÅ¼ pokrytych w artykule: {topics}')

    if stop_names:
        sections.append(f'\nğŸ›‘ STOP, NIE UÅ»YWAJ: {", ".join(f"{s}" for s in stop_names[:5])}')

    if style:
        forbidden = style.get("forbidden_phrases") or []
        if forbidden:
            sections.append(f'ZAKAZANE zwroty: {", ".join(forbidden[:5])}')

    if pre_batch and pre_batch.get("article_memory"):
        mem = pre_batch["article_memory"]
        if isinstance(mem, dict):
            topics = mem.get("topics_covered") or []
            if topics:
                topic_names = [t if isinstance(t, str) else t.get("topic", "") for t in topics[:6]]
                sections.append(f'\nTematy z artykuÅ‚u (nie powtarzaj): {", ".join(topic_names)}')

    if instructions:
        sections.append(f'\n{instructions}')

    sections.append("""
â•â•â• FORMAT â•â•â•
h2: NajczÄ™Å›ciej zadawane pytania

h3: [Pytanie, 5-10 sÅ‚Ã³w, zaczynaj od Jak/Czy/Co/Dlaczego/Ile]
[OdpowiedÅº 60-120 sÅ‚Ã³w]
â†’ Zdanie 1: BEZPOÅšREDNIA odpowiedÅº
â†’ Zdanie 2-3: rozwiniÄ™cie z konkretem
â†’ Zdanie 4: praktyczna wskazÃ³wka lub wyjÄ…tek

Napisz 4-6 pytaÅ„. Pisz TYLKO treÅ›Ä‡, bez komentarzy.""")

    return "\n\n".join(sections)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# H2 PLAN PROMPT BUILDER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_h2_plan_system_prompt():
    """System prompt for H2 plan generation."""
    return (
        "JesteÅ› ekspertem SEO z 10-letnim doÅ›wiadczeniem w planowaniu architektury treÅ›ci. "
        "Tworzysz logiczne, wyczerpujÄ…ce struktury nagÅ‚Ã³wkÃ³w H2, ktÃ³re pokrywajÄ… temat kompleksowo "
        "i dajÄ… przewagÄ™ nad konkurencjÄ… dziÄ™ki pokryciu luk treÅ›ciowych."
    )


def build_h2_plan_user_prompt(main_keyword, mode, s1_data, all_user_phrases, user_h2_hints=None):
    """Build readable H2 plan prompt from S1 analysis data."""
    s1_data = s1_data or {}
    competitor_h2 = s1_data.get("competitor_h2_patterns") or []
    suggested_h2s = (s1_data.get("content_gaps") or {}).get("suggested_new_h2s", [])
    content_gaps = s1_data.get("content_gaps") or {}
    causal_triplets = s1_data.get("causal_triplets") or {}
    paa = s1_data.get("paa") or s1_data.get("paa_questions") or []
    # v52.0: Related searches - Google sugeruje te pytania/frazy uÅ¼ytkownikom
    serp_analysis = s1_data.get("serp_analysis") or {}
    related_searches = (s1_data.get("related_searches")
                        or serp_analysis.get("related_searches") or [])

    sections = []

    mode_desc = "standard = peÅ‚ny artykuÅ‚" if mode == "standard" else "fast = krÃ³tki artykuÅ‚, max 3 sekcje"
    sections.append(f"""HASÅO GÅÃ“WNE: {main_keyword}
TRYB: {mode} ({mode_desc})""")

    if competitor_h2:
        # Sort by count descending if available
        def _h2_count(h):
            if isinstance(h, dict):
                return h.get("count", h.get("sources", 0))
            return 0
        sorted_h2 = sorted(competitor_h2[:30], key=_h2_count, reverse=True)
        total_sources = max((_h2_count(sorted_h2[0]) for _ in [1]), default=1) or 1

        lines = ["â•â•â• WZORCE H2 KONKURENCJI â€” posortowane po popularnoÅ›ci â•â•â•",
                 "Liczba przy H2 = ilu konkurentÃ³w uÅ¼ywa tego tematu.",
                 "H2 z wysokÄ… liczbÄ… = MUST HAVE w Twoim artykule (uÅ¼ytkownicy tego szukajÄ…)."]
        for i, h in enumerate(sorted_h2[:20], 1):
            if isinstance(h, dict):
                pattern = h.get("text", h.get("pattern", h.get("h2", str(h))))
                count = _h2_count(h)
                bar = "â–ˆ" * min(count, 8)
                lines.append(f"  {i:2}. [{bar:<8}] {count}Ã— â€” {pattern}")
            elif isinstance(h, str):
                lines.append(f"  {i:2}. {h}")
        sections.append("\n".join(lines))

    if suggested_h2s:
        lines = ["â•â•â• SUGEROWANE NOWE H2 (luki, tego NIKT z konkurencji nie pokrywa) â•â•â•"]
        for h in suggested_h2s[:10]:
            h_text = h if isinstance(h, str) else h.get("h2", h.get("title", str(h)))
            lines.append(f"  â€¢ {h_text}")
        sections.append("\n".join(lines))

    # Content gaps: ordered by priority (GPT prompt: PAA_UNANSWERED > DEPTH_MISSING > SUBTOPIC_MISSING)
    gap_priority_map = {
        "paa_unanswered": ("ğŸ”´ HIGH", "PAA bez odpowiedzi"),
        "depth_missing": ("ğŸŸ¡ MED-HIGH", "Brak gÅ‚Ä™bi"),
        "subtopic_missing": ("ğŸŸ¢ MED", "BrakujÄ…cy podtemat"),
        "gaps": ("", "Luka"),
    }
    all_gaps = []
    for key in ("paa_unanswered", "depth_missing", "subtopic_missing", "gaps"):
        priority, label = gap_priority_map.get(key, ("", ""))
        items = content_gaps.get(key) or []
        for item in items[:5]:
            gap_text = item if isinstance(item, str) else item.get("gap", item.get("topic", str(item)))
            if gap_text and gap_text not in [g[0] for g in all_gaps]:
                all_gaps.append((gap_text, priority, label))
    if all_gaps:
        lines = ["â•â•â• LUKI TREÅšCIOWE (tematy do pokrycia, priorytet od najwyÅ¼szego) â•â•â•"]
        for gap_text, priority, label in all_gaps[:10]:
            prefix = f"[{priority}] " if priority else ""
            lines.append(f"  â€¢ {prefix}{gap_text}")
        sections.append("\n".join(lines))

    if paa:
        lines = ["â•â•â• PYTANIA PAA (People Also Ask z Google) â•â•â•"]
        for q in paa[:8]:
            q_text = q.get("question", q) if isinstance(q, dict) else q
            if q_text:
                lines.append(f"  â“ {q_text}")
        sections.append("\n".join(lines))

    # v52.0: Related searches - Google podpowiada te frazy po wpisaniu main_keyword.
    # ZawierajÄ… intencje ktÃ³rych czÄ™sto BRAK w H2 konkurencji (np. "warunkowe umorzenie",
    # "doÅ¼ywotni zakaz", "organizmie wynosi") - waÅ¼ny signal dla tematycznego pokrycia H2.
    if related_searches:
        rs_texts = []
        for rs in related_searches[:12]:
            rs_t = rs if isinstance(rs, str) else (rs.get("query", "") or rs.get("text", ""))
            if rs_t:
                rs_texts.append(rs_t)
        if rs_texts:
            lines = ["â•â•â• RELATED SEARCHES (Google podpowiada po main_keyword) â•â•â•",
                     "UÅ¼yj tych fraz jako wskazÃ³wek tematycznych przy tworzeniu H2.",
                     "Wiele z nich to podtematy ktÃ³rych BRAK u konkurencji â€” Twoja szansa:"]
            for rs_t in rs_texts:
                lines.append(f"  ğŸ” {rs_t}")
            sections.append("\n".join(lines))

    triplet_list = (causal_triplets.get("chains") or causal_triplets.get("singles")
                    or causal_triplets.get("triplets") or [])[:8]
    if triplet_list:
        lines = ["â•â•â• PRZYCZYNOWE ZALEÅ»NOÅšCI (causeâ†’effect z konkurencji) â•â•â•",
                 "Confidence: ğŸ”´ â‰¥0.9 UÅ»YJ | ğŸŸ¡ â‰¥0.6 gdy pasuje | ğŸŸ¢ <0.6 opcjonalnie",
                 "is_chain=True (Aâ†’Bâ†’C) = najcenniejsze. Buduj logiczny przepÅ‚yw"]
        for t in triplet_list:
            if isinstance(t, dict):
                cause = t.get("cause", t.get("subject", ""))
                effect = t.get("effect", t.get("object", ""))
                conf = t.get("confidence", 0)
                is_chain = t.get("is_chain", False)
                
                # Priority indicator
                if conf >= 0.9:
                    ind = "ğŸ”´"
                elif conf >= 0.6:
                    ind = "ğŸŸ¡"
                else:
                    ind = "ğŸŸ¢"
                chain_tag = " [CHAIN]" if is_chain else ""
                conf_str = f" ({conf:.1f})" if conf else ""
                lines.append(f"  {ind} {cause} â†’ {effect}{conf_str}{chain_tag}")
            elif isinstance(t, str):
                lines.append(f"  â€¢ {t}")
        sections.append("\n".join(lines))

    if user_h2_hints:
        h2_hints_list = "\n".join(f'  â€¢ "{h}"' for h in user_h2_hints[:10])
        sections.append(f"""â•â•â• FRAZY H2 UÅ»YTKOWNIKA â•â•â•

UÅ¼ytkownik podaÅ‚ te frazy z myÅ›lÄ… o nagÅ‚Ã³wkach H2.
Wykorzystaj je w nagÅ‚Ã³wkach tam, gdzie brzmiÄ… naturalnie po polsku.
Nie musisz uÅ¼yÄ‡ kaÅ¼dej, ale nie ignoruj ich. Dopasuj z wyczuciem.

JeÅ›li fraza brzmi sztucznie jako nagÅ‚Ã³wek, przeformuÅ‚uj lub pomiÅ„ (trafi do treÅ›ci).

FRAZY H2:
{h2_hints_list}""")

    if all_user_phrases:
        phrases_text = ", ".join(f'"{p}"' for p in all_user_phrases[:15])
        sections.append(f"""â•â•â• KONTEKST TEMATYCZNY (frazy BASIC/EXTENDED) â•â•â•

PoniÅ¼sze frazy bÄ™dÄ… uÅ¼yte W TREÅšCI artykuÅ‚u (nie w nagÅ‚Ã³wkach).
PodajÄ™ je Å¼ebyÅ› wiedziaÅ‚ jaki zakres tematyczny artykuÅ‚ musi pokryÄ‡
i zaplanowaÅ‚ H2 tak, by kaÅ¼da fraza miaÅ‚a naturalnÄ… sekcjÄ™:

{phrases_text}""")

    fast_note = "Tryb fast: DOKÅADNIE 3 sekcje + FAQ (4 H2 Å‚Ä…cznie)." if mode == "fast" else ""
    
    # v50.8 FIX 50: H2 scaling: minimum 5-6 sekcji nawet dla krÃ³tkich artykuÅ‚Ã³w.
    # WiÄ™cej sekcji = lepsza struktura, lepsze SEO, Å‚atwiejsze skanowanie.
    length_analysis = s1_data.get("length_analysis") or {}
    rec_length = length_analysis.get("recommended") or s1_data.get("recommended_length") or 0
    median_length = length_analysis.get("median") or s1_data.get("median_length") or 0
    
    if mode != "fast":
        target = rec_length or (median_length * 2) or 1500
        if target <= 1000:
            h2_range = "5-6"
            h2_min, h2_max = 5, 6
        elif target <= 2000:
            h2_range = "6-8"
            h2_min, h2_max = 6, 8
        elif target <= 3500:
            h2_range = "7-9"
            h2_min, h2_max = 7, 9
        else:
            h2_range = "8-12"
            h2_min, h2_max = 8, 12
        
        fast_note = (
            f"Tryb standard: {h2_range} sekcji + FAQ ({h2_min+1}-{h2_max+1} H2 Å‚Ä…cznie).\n"
            f"   UWAGA: Rekomendowana dÅ‚ugoÅ›Ä‡ artykuÅ‚u: ~{target} sÅ‚Ã³w (mediana konkurencji: {median_length}).\n"
            f"   KaÅ¼da sekcja H2 = ~{target // (h2_max + 1)}-{target // h2_min} sÅ‚Ã³w.\n"
            f"   NIE GENERUJ wiÄ™cej niÅ¼ {h2_max + 1} H2 (wliczajÄ…c FAQ)!"
        )
    
    h2_hint_rule = ("UwzglÄ™dnij frazy H2 uÅ¼ytkownika w nagÅ‚Ã³wkach, o ile brzmiÄ… naturalnie."
                    if user_h2_hints else "Dobierz nagÅ‚Ã³wki na podstawie S1 i luk treÅ›ciowych.")

    sections.append(f"""â•â•â• ZASADY â•â•â•

1. LICZBA H2: {fast_note}
2. OSTATNI H2 MUSI byÄ‡: "NajczÄ™Å›ciej zadawane pytania"
3. Pokryj najwaÅ¼niejsze wzorce z konkurencji + luki treÅ›ciowe (przewaga nad konkurencjÄ…)
4. {h2_hint_rule}
5. Logiczna narracja: od ogÃ³Å‚u do szczegÃ³Å‚u, chronologicznie, lub problemowo
6. NIE powtarzaj hasÅ‚a gÅ‚Ã³wnego dosÅ‚ownie w kaÅ¼dym H2
7. H2 muszÄ… brzmieÄ‡ naturalnie po polsku, Å¼adnego keyword stuffingu

â•â•â• FORMAT ODPOWIEDZI â•â•â•

Odpowiedz TYLKO JSON array, bez markdown, bez komentarzy:
["H2 pierwszy", "H2 drugi", ..., "NajczÄ™Å›ciej zadawane pytania"]""")

    return "\n\n".join(sections)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CATEGORY DESCRIPTION PROMPT BUILDERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Separate prompt system for e-commerce category page descriptions.
# Key differences vs article: commercial intent, 200-1200 words,
# keyword density 1.0-2.0%, entity salience >0.30, 3-block structure
# (intro above products + SEO content below + FAQ).
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def build_category_system_prompt(pre_batch, batch_type, category_data=None):
    """
    System prompt for e-commerce category descriptions.
    Different role, goal, audience, tone and rules vs article prompt.
    """
    pre_batch = pre_batch or {}
    category_data = category_data or {}

    parts = []

    store_name = category_data.get("store_name") or "sklep"
    store_desc = category_data.get("store_description") or ""
    brand_voice = category_data.get("brand_voice") or ""

    # â”€â”€ ROLA â”€â”€
    store_ctx = f" dla {store_name}" if store_name != "sklep" else ""
    store_desc_line = f"\n{store_desc}" if store_desc else ""
    parts.append(f"""<role>
JesteÅ› doÅ›wiadczonym copywriterem e-commerce{store_ctx}{store_desc_line}.
Specjalizujesz siÄ™ w opisach kategorii sklepÃ³w internetowych,
ktÃ³re Å‚Ä…czÄ… SEO z konwersjÄ… zakupowÄ….

Nie jesteÅ› blogerem â€” piszesz tekst sprzedaÅ¼owy, nie edukacyjny.
Nie jesteÅ› chatbotem â€” piszesz jak ekspert produktowy.
TwÃ³j tekst ma wspieraÄ‡ decyzjÄ™ zakupowÄ…, nie edukowaÄ‡ encyklopedycznie.
</role>""")

    # â”€â”€ CEL â”€â”€
    parts.append("""<goal>
Twoim celem jest napisanie opisu kategorii e-commerce, ktÃ³ry:
  â€¢ wspiera intencjÄ™ komercyjnÄ…/transakcyjnÄ… uÅ¼ytkownika,
  â€¢ naturalnie zawiera sÅ‚owa kluczowe (gÄ™stoÅ›Ä‡ 1,0â€“2,0%),
  â€¢ buduje entity salience >0,30 dla gÅ‚Ã³wnej encji,
  â€¢ uÅ¼ywa konkretnych nazw produktÃ³w, cen, cech â€” nie ogÃ³lnikÃ³w,
  â€¢ pomaga kupujÄ…cemu podjÄ…Ä‡ decyzjÄ™ zakupowÄ….

80% elementÃ³w transakcyjnych, 20% informacyjnych.
SEO jest narzÄ™dziem konwersji, nie celem samym w sobie.
</goal>""")

    # â”€â”€ ODBIORCA â”€â”€
    target = category_data.get("target_audience") or ""
    target_line = f"\nGrupa docelowa: {target}" if target else ""
    parts.append(f"""<audience>
KupujÄ…cy z intencjÄ… zakupowÄ… â€” szuka produktu, porÃ³wnuje opcje,
chce wiedzieÄ‡ dlaczego kupiÄ‡ tutaj i jaki produkt wybraÄ‡.{target_line}
Pisz jakbyÅ› doradzaÅ‚ przyjacielowi, ktÃ³ry prosi o szczerÄ… rekomendacjÄ™.
</audience>""")

    # â”€â”€ TON I STYL â”€â”€
    voice_line = f"\nBrand voice: {brand_voice}" if brand_voice else ""
    parts.append(f"""<tone>
Ton: autorytatywny, pomocny, zwiÄ™zÅ‚y.
Perspektywa: â€my" (sklep) lub trzecia osoba â€” zaleÅ¼y od brand voice.
Unikaj: â€szeroki wybÃ³r", â€coÅ› dla kaÅ¼dego", â€nie szukaj dalej",
  â€niezaleÅ¼nie czy jesteÅ› X czy Y", â€jedyne miejsce".{voice_line}
</tone>""")

    # â”€â”€ EPISTEMOLOGIA â”€â”€
    parts.append("""<epistemology>
Å¹RÃ“DÅA WIEDZY:
  1. Dane wejÅ›ciowe: produkty, ceny, cechy, USP â€” podane wprost
  2. Konkurencja z SERP (podane w danych) â€” czytasz fakty, NIE kopiujesz
  3. Wiedza produktowa z podanych danych â€” TYLKO to co masz

âŒ ZAKAZ: nie wymyÅ›laj produktÃ³w, cen, recenzji, nagrÃ³d, certyfikatÃ³w.
âŒ ZAKAZ: nie podawaj liczb/statystyk ktÃ³rych nie masz w danych.
JEÅšLI NIE WIESZ â†’ OPUÅšÄ†, nie zmyÅ›laj.
</epistemology>""")

    # â”€â”€ STRUKTURA KATEGORII â”€â”€
    cat_type = category_data.get("category_type", "subcategory")
    if cat_type == "parent":
        struct_desc = """STRUKTURA â€” KATEGORIA NADRZÄ˜DNA (200â€“500 sÅ‚Ã³w):
  Blok 1 â€” INTRO nad produktami (50â€“100 sÅ‚Ã³w):
    Keyword w pierwszym zdaniu, krÃ³tki opis asortymentu, 1â€“2 USP,
    linki do podkategorii. Widoczne bez â€czytaj wiÄ™cej".
  Blok 2 â€” TREÅšÄ† SEO pod produktami (100â€“300 sÅ‚Ã³w):
    1â€“2 sekcje H2: przeglÄ…d podkategorii, dlaczego warto kupiÄ‡ u nas.
    Nawigacyjny charakter â€” kieruj do podkategorii.
  Blok 3 â€” FAQ (2â€“3 pytania, 80â€“150 sÅ‚Ã³w):
    Pytania zakupowe, nie encyklopedyczne. KaÅ¼de jako H3."""
    else:
        struct_desc = """STRUKTURA â€” PODKATEGORIA (500â€“1200 sÅ‚Ã³w):
  Blok 1 â€” INTRO nad produktami (50â€“150 sÅ‚Ã³w):
    Keyword w pierwszym zdaniu, opis asortymentu, 1â€“2 USP,
    opcjonalnie linki do powiÄ…zanych kategorii. Widoczne bez â€czytaj wiÄ™cej".
  Blok 2 â€” TREÅšÄ† SEO pod produktami (400â€“800 sÅ‚Ã³w):
    2â€“4 sekcje H2 z wariacjami keywordu:
    - â€Jak wybraÄ‡ [kategoria]" â€” poradnik wyboru, kluczowe cechy
    - â€Rodzaje [kategorii] w naszej ofercie" â€” przeglÄ…d asortymentu
    - â€Dlaczego warto kupiÄ‡ u nas" â€” USP, przewagi
    KaÅ¼da sekcja 100â€“200 sÅ‚Ã³w z encjami, linkami, atrybutami produktÃ³w.
  Blok 3 â€” FAQ (3â€“6 pytaÅ„, 150â€“300 sÅ‚Ã³w):
    Pytania zakupowe (nie â€czym jest [kategoria]").
    KaÅ¼de pytanie jako H3, odpowiedÅº 40â€“80 sÅ‚Ã³w."""

    parts.append(f"<category_structure>\n{struct_desc}\n</category_structure>")

    # â”€â”€ ZASADY PISANIA â”€â”€
    parts.append("""<rules>

KEYWORD DENSITY: 1,0â€“2,0% (wyÅ¼sza niÅ¼ w artykule blogowym).
  Keyword gÅ‚Ã³wny: naturalnie w 1. akapicie, min. 1 H2, rozÅ‚oÅ¼ony w tekÅ›cie.
  Keywords drugorzÄ™dne: kaÅ¼dy min. 1Ã— naturalnie.

ENTITY SALIENCE: cel >0,30 dla gÅ‚Ã³wnej encji.
  Zamiast â€oferujemy kurtki" â†’ â€przeglÄ…daj nasze parki, bomberki,
  puchÃ³wki i trencze z weÅ‚ny, skÃ³ry i zamszu".
  Entity-rich sformuÅ‚owania: typy produktÃ³w, materiaÅ‚y, technologie,
  zastosowania, marki, cechy uÅ¼ytkownika.

PASSAGE-FIRST: Intro musi samodzielnie funkcjonowaÄ‡ jako AI-extractable summary.
  Pierwsze 2â€“3 zdania = standalone odpowiedÅº na search intent.

LISTY HTML: Przy wyliczeniach 3+ elementÃ³w â€” ZAWSZE lista <ul>/<ol>.

DÅUGOÅšÄ† ZDAÅƒ:
  Max bezwzglÄ™dne: 35 sÅ‚Ã³w. Cel Å›redniej: 12â€“18 sÅ‚Ã³w/zdanie.
  20% krÃ³tkich (do 8 sÅ‚Ã³w), 60% Å›rednich (9â€“18), 20% dÅ‚ugich (19â€“28).

SPACING:
  MAIN keyword: ~60 sÅ‚Ã³w odstÄ™pu. BASIC: ~80. EXTENDED: ~120.

ANTI-ANAPHORA: Ta sama fraza NIE MOÅ»E otwieraÄ‡ >2 kolejnych zdaÅ„.

ANTI-AI â€” BEZWZGLÄ˜DNY ZAKAZ fraz:
  â€warto zauwaÅ¼yÄ‡/podkreÅ›liÄ‡", â€co istotne/kluczowe",
  â€przyjrzyjmy siÄ™", â€w tym kontekÅ›cie", â€podsumowujÄ…c",
  â€kaÅ¼dorazowo naleÅ¼y", â€ze wzglÄ™du na zÅ‚oÅ¼onoÅ›Ä‡",
  â€szeroki wybÃ³r", â€coÅ› dla kaÅ¼dego", â€nie szukaj dalej",
  â€niezaleÅ¼nie czy jesteÅ› X czy Y", â€jedyne miejsce".

LINKI WEWNÄ˜TRZNE: 3â€“8 kontekstowych na 300â€“500 sÅ‚Ã³w.
  Cele: podkategorie > bestsellery > powiÄ…zane kategorie > blog.
  Anchor text opisowy i zrÃ³Å¼nicowany.

CTA: Nad foldem w intro. Wspieraj decyzjÄ™: â€ZnajdÅº idealne [produkt]",
  â€Filtruj wedÅ‚ug [atrybut]". Nie agresywna sprzedaÅ¼.

POLSZCZYZNA (NKJP):
  Przecinki przed: Å¼e, ktÃ³ry, poniewaÅ¼, gdyÅ¼, aby, Å¼eby.
  Poprawne kolokacje. Mieszaj przypadki gramatyczne.
  Odmiana frazy = jedno uÅ¼ycie (fleksja).

FORMAT: h2:/h3: dla nagÅ‚Ã³wkÃ³w. Zero markdown, HTML, gwiazdek.

SWAP TEST: JeÅ›li tekst mÃ³gÅ‚by dziaÅ‚aÄ‡ na stronie konkurencji bez zmian,
  jest zbyt generyczny â€” dodaj konkrety (produkty, ceny, USP).

</rules>""")

    # â”€â”€ FEW-SHOT â”€â”€
    parts.append("""<examples>

PRZYKÅAD ZÅY â€” czego NIE pisaÄ‡:
<example_bad>
Witaj w naszym sklepie! Oferujemy szeroki wybÃ³r butÃ³w do biegania
dla kaÅ¼dego. NiezaleÅ¼nie czy jesteÅ› poczÄ…tkujÄ…cym biegaczem czy
zaawansowanym maratoÅ„czykiem, znajdziesz coÅ› dla siebie.
Nie szukaj dalej â€” to jedyne miejsce, ktÃ³rego potrzebujesz.
</example_bad>
BÅ‚Ä™dy: generyczne frazy, brak konkretÃ³w, brak produktÃ³w/cen,
frazesy AI, przeszÅ‚oby na dowolnej stronie konkurencji.

PRZYKÅAD DOBRY â€” tak pisz:
<example_good>
Damskie buty do biegania od Nike, ASICS i Brooks â€” od 299 do 1 199 zÅ‚.
Bestseller sezonu: Nike Air Zoom Pegasus 41 (4,7â˜…, 312 recenzji)
Å‚Ä…czy responsywnÄ… piankÄ™ React z siateczkÄ… Flyknit o przepuszczalnoÅ›ci
potwierdzonej testem wilgotnoÅ›ci. Dla biegaczek szukajÄ…cych stabilizacji
przy pronacji â€” ASICS Gel-Kayano 31 z podwÃ³jnÄ… gÄ™stoÅ›ciÄ… pianki
w Å›rÃ³dstopiu. Darmowy zwrot 30 dni, wysyÅ‚ka w 24h.
</example_good>
Zalety: konkretne produkty z cenami, dane z recenzji, technologie,
USP sklepu, entity-rich, nie przejdzie u konkurencji bez zmian.

</examples>""")

    return "\n\n".join(parts)


def build_category_user_prompt(pre_batch, h2, batch_type, article_memory=None, category_data=None):
    """
    User prompt for e-commerce category descriptions.
    Injects category-specific data: store info, products, hierarchy, USP.
    """
    pre_batch = pre_batch or {}
    category_data = category_data or {}
    sections = []

    # â”€â”€ RE-ANCHOR â”€â”€
    sections.append(
        "Piszesz opis kategorii e-commerce â€” ton pomocny, "
        "konkretny, wspierajÄ…cy decyzjÄ™ zakupowÄ…. "
        "Zasady w system prompcie."
    )

    # â”€â”€ OPENING PATTERN (rotacja jak w artykule, ale z komercyjnym nachyleniem) â”€â”€
    _CAT_PATTERNS = [
        ("A", "KONKRET PRODUKTOWY",
         "Zacznij od konkretnego produktu, ceny lub cechy. "
         "Np: 'Nike Pegasus 41 od 549 zÅ‚ â€” bestseller z 312 recenzjami...'"),
        ("B", "ZAKRES/STATYSTYKA",
         "Zacznij od zakresu, liczby lub faktu. "
         "Np: 'Ponad 200 modeli butÃ³w do biegania od 15 marek...'"),
        ("C", "POTRZEBA KUPUJÄ„CEGO",
         "Zacznij od potrzeby klienta. "
         "Np: 'Szukasz buta na maraton z amortyzacjÄ… na twardym podÅ‚oÅ¼u?'"),
        ("D", "USP/WYRÃ“Å»NIK",
         "Zacznij od przewagi sklepu. "
         "Np: 'Darmowy zwrot 30 dni i dobÃ³r rozmiaru z ekspertem...'"),
    ]
    batch_num = pre_batch.get("batch_number", 1) or 1
    pattern_idx = (batch_num - 1) % len(_CAT_PATTERNS)
    p_letter, p_name, p_desc = _CAT_PATTERNS[pattern_idx]
    sections.append(
        f"OTWARCIE â€” wzorzec {p_letter} ({p_name}):\n{p_desc}"
    )

    # â”€â”€ CATEGORY CONTEXT â”€â”€
    cat_ctx_parts = []
    cat_name = category_data.get("category_name") or pre_batch.get("main_keyword", "")
    if isinstance(cat_name, dict):
        cat_name = cat_name.get("keyword", "")
    cat_type = category_data.get("category_type", "subcategory")
    hierarchy = category_data.get("hierarchy") or ""
    store_name = category_data.get("store_name") or ""
    usp = category_data.get("usp") or ""
    products = category_data.get("products") or ""
    bestseller = category_data.get("bestseller") or ""
    price_range = category_data.get("price_range") or ""

    cat_ctx_parts.append(f"Kategoria: {cat_name}")
    cat_ctx_parts.append(f"Typ: {'nadrzÄ™dna' if cat_type == 'parent' else 'podkategoria'}")
    if hierarchy:
        cat_ctx_parts.append(f"Hierarchia: {hierarchy}")
    if store_name:
        cat_ctx_parts.append(f"Sklep: {store_name}")
    if usp:
        cat_ctx_parts.append(f"USP: {usp}")
    if products:
        cat_ctx_parts.append(f"Produkty:\n{products}")
    if bestseller:
        cat_ctx_parts.append(f"Bestseller: {bestseller}")
    if price_range:
        cat_ctx_parts.append(f"Zakres cenowy: {price_range}")

    sections.append("â•â•â• DANE KATEGORII â•â•â•\n" + "\n".join(cat_ctx_parts))

    # â”€â”€ REUSE ARTICLE FORMATTERS where applicable â”€â”€
    _schema_guard(pre_batch)

    formatters = [
        lambda: _fmt_batch_header(pre_batch, h2, batch_type),
        lambda: _fmt_keywords(pre_batch),
        lambda: _fmt_smart_instructions(pre_batch),
        lambda: _fmt_semantic_plan(pre_batch, h2),
        lambda: _fmt_coverage_density(pre_batch),
        lambda: _fmt_continuation(pre_batch),
        lambda: _fmt_article_memory(article_memory),
        lambda: _fmt_h2_remaining(pre_batch),
        lambda: _fmt_entity_salience(pre_batch),
        lambda: _fmt_serp_enrichment(pre_batch),
        lambda: _fmt_natural_polish(pre_batch),
        lambda: _fmt_style(pre_batch),
        lambda: _fmt_output_format(h2, batch_type),
    ]

    for fmt in formatters:
        try:
            result = fmt()
            if result:
                sections.append(result)
        except Exception:
            pass

    return "\n\n".join(sections)
