"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BRAJEN PROMPT BUILDER v1.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Converts raw pre_batch data into optimized, readable prompts.

Replaces json.dumps() spam with structured natural language
that Claude can actually follow.

Architecture:
  SYSTEM PROMPT = Expert persona + Writing techniques
  USER PROMPT   = Structured instructions from data
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import json


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SYSTEM PROMPT BUILDER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_system_prompt(pre_batch, batch_type):
    """
    Build system prompt = expert persona + writing rules.
    Uses gpt_instructions_v39 (writing techniques from API) as the core,
    with a proper persona wrapper.
    """
    gpt_instructions = pre_batch.get("gpt_instructions_v39", "")
    gpt_prompt = pre_batch.get("gpt_prompt", "")

    parts = []

    # â”€â”€ Expert persona â”€â”€
    parts.append(
        "JesteÅ› doÅ›wiadczonym polskim copywriterem SEO z 10-letnim staÅ¼em. "
        "Piszesz naturalnie, merytorycznie i angaÅ¼ujÄ…co. "
        "TwÃ³j tekst nie brzmi jak AI â€” brzmi jak ekspert piszÄ…cy dla ludzi."
    )

    # â”€â”€ Writing techniques from API (if available) â”€â”€
    if gpt_instructions:
        parts.append(gpt_instructions)

    # â”€â”€ Batch context from API (structure, lengths) â”€â”€
    if gpt_prompt:
        parts.append(gpt_prompt)

    # â”€â”€ Core rules (always) â”€â”€
    parts.append("""ZASADY PISANIA:
â€¢ PASSAGE-FIRST: KaÅ¼dy akapit zaczynaj od konkretnej odpowiedzi, potem rozwijaj.
â€¢ BURSTINESS: Mieszaj dÅ‚ugoÅ›Ä‡ zdaÅ„ â€” krÃ³tkie (8 sÅ‚Ã³w) z dÅ‚uÅ¼szymi (20-25 sÅ‚Ã³w).
â€¢ ANTI-AI: Unikaj fraz-klisz: "warto zauwaÅ¼yÄ‡", "naleÅ¼y podkreÅ›liÄ‡", "w dzisiejszych czasach", "kluczowe jest", "nie ulega wÄ…tpliwoÅ›ci". Brzmi to sztucznie.
â€¢ NATURALNOÅšÄ†: Pisz jak ekspert tÅ‚umaczÄ…cy temat znajomemu â€” konkretnie, bez lania wody.
â€¢ FORMAT: UÅ¼ywaj wyÅ‚Ä…cznie formatu h2:/h3: dla nagÅ‚Ã³wkÃ³w. Å»adnego markdown, HTML ani gwiazdek.""")

    return "\n\n".join(parts)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# USER PROMPT BUILDER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_user_prompt(pre_batch, h2, batch_type, article_memory=None):
    """
    Main user prompt builder.
    Converts ALL pre_batch fields into readable, actionable instructions.
    """
    sections = []

    sections.append(_fmt_batch_header(pre_batch, h2, batch_type))
    sections.append(_fmt_intro_guidance(pre_batch, batch_type))
    sections.append(_fmt_smart_instructions(pre_batch))
    sections.append(_fmt_keywords(pre_batch))
    sections.append(_fmt_semantic_plan(pre_batch, h2))
    sections.append(_fmt_entities(pre_batch))
    sections.append(_fmt_ngrams(pre_batch))
    sections.append(_fmt_serp_enrichment(pre_batch))
    sections.append(_fmt_continuation(pre_batch))
    sections.append(_fmt_article_memory(article_memory))
    sections.append(_fmt_coverage_density(pre_batch))
    sections.append(_fmt_style(pre_batch))
    sections.append(_fmt_legal_medical(pre_batch))
    sections.append(_fmt_experience_markers(pre_batch))
    sections.append(_fmt_causal_context(pre_batch))
    sections.append(_fmt_h2_remaining(pre_batch))
    sections.append(_fmt_output_format(h2, batch_type))

    # Filter empty sections
    return "\n\n".join(s for s in sections if s)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECTION FORMATTERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _fmt_batch_header(pre_batch, h2, batch_type):
    batch_number = pre_batch.get("batch_number", 1)
    total_batches = pre_batch.get("total_planned_batches", 1)
    batch_length = pre_batch.get("batch_length") or {}

    min_w = batch_length.get("min_words", 350)
    max_w = batch_length.get("max_words", 500)

    section_length = pre_batch.get("section_length_guidance") or {}
    length_hint = ""
    if section_length:
        suggested = section_length.get("suggested_words") or section_length.get("target_words")
        if suggested:
            length_hint = f"\nSugerowana dÅ‚ugoÅ›Ä‡ tej sekcji: ~{suggested} sÅ‚Ã³w."

    return f"""â•â•â• BATCH {batch_number}/{total_batches} â€” {batch_type} â•â•â•
Sekcja H2: "{h2}"
DÅ‚ugoÅ›Ä‡: {min_w}-{max_w} sÅ‚Ã³w{length_hint}
Zaczynaj DOKÅADNIE od: h2: {h2}"""


def _fmt_intro_guidance(pre_batch, batch_type):
    if batch_type not in ("INTRO", "intro"):
        return ""
    guidance = pre_batch.get("intro_guidance", "")
    if not guidance:
        return ""

    if isinstance(guidance, dict):
        hook = guidance.get("hook", "")
        angle = guidance.get("angle", "")
        parts = []
        if hook:
            parts.append(f"Hak otwierajÄ…cy: {hook}")
        if angle:
            parts.append(f"KÄ…t artykuÅ‚u: {angle}")
        return "â•â•â• WPROWADZENIE â•â•â•\n" + "\n".join(parts) if parts else ""

    return f"â•â•â• WPROWADZENIE â•â•â•\n{guidance}"


def _fmt_smart_instructions(pre_batch):
    """Smart instructions from enhanced_pre_batch â€” THE most valuable field."""
    enhanced = pre_batch.get("enhanced") or {}
    smart = enhanced.get("smart_instructions_formatted", "")
    if smart:
        return f"â•â•â• INSTRUKCJE DLA TEGO BATCHA â•â•â•\n{smart[:1000]}"
    return ""


def _fmt_keywords(pre_batch):
    keywords_info = pre_batch.get("keywords") or {}
    keyword_limits = pre_batch.get("keyword_limits") or {}
    soft_caps = pre_batch.get("soft_cap_recommendations") or {}

    # â”€â”€ MUST USE â”€â”€
    must_raw = keywords_info.get("basic_must_use", [])
    must_lines = []
    for kw in must_raw:
        if isinstance(kw, dict):
            name = kw.get("keyword", "")
            tmin = kw.get("target_min", 1)
            tmax = kw.get("target_max", "")
            remaining = kw.get("remaining", "")
            extra = f" â€” uÅ¼yj min {tmin}Ã—" if tmin else ""
            if remaining:
                extra = f" â€” jeszcze {remaining}Ã— do uÅ¼ycia"
            must_lines.append(f'  â€¢ "{name}"{extra}')
        else:
            must_lines.append(f'  â€¢ "{kw}"')

    # â”€â”€ EXTENDED â”€â”€
    ext_raw = keywords_info.get("extended_this_batch", [])
    ext_lines = []
    for kw in ext_raw:
        name = kw.get("keyword", kw) if isinstance(kw, dict) else kw
        ext_lines.append(f'  â€¢ "{name}"')

    # â”€â”€ STOP â”€â”€
    stop_raw = keyword_limits.get("stop_keywords") or []
    stop_lines = []
    for s in stop_raw:
        if isinstance(s, dict):
            name = s.get("keyword", "")
            current = s.get("current_count", s.get("current", "?"))
            max_c = s.get("max_count", s.get("max", "?"))
            stop_lines.append(f'  â€¢ "{name}" (juÅ¼ {current}Ã—, limit {max_c})')
        else:
            stop_lines.append(f'  â€¢ "{s}"')

    # â”€â”€ CAUTION â”€â”€
    caution_raw = keyword_limits.get("caution_keywords") or []
    caution_lines = []
    for c in caution_raw:
        name = c.get("keyword", c) if isinstance(c, dict) else c
        caution_lines.append(f'  â€¢ "{name}" â€” max 1Ã—')

    # â”€â”€ SOFT CAPS (merge context) â”€â”€
    soft_notes = []
    if soft_caps:
        for kw_name, info in soft_caps.items():
            if isinstance(info, dict):
                action = info.get("action", "")
                if action and action != "OK":
                    soft_notes.append(f'  â„¹ï¸ "{kw_name}": {action}')

    # â”€â”€ Build section â”€â”€
    parts = ["â•â•â• FRAZY KLUCZOWE â•â•â•"]

    if must_lines:
        parts.append("ğŸ”´ OBOWIÄ„ZKOWE (wpleÄ‡ naturalnie w tekst):")
        parts.extend(must_lines)

    if ext_lines:
        parts.append("\nğŸŸ¡ ROZSZERZONE (uÅ¼yj jeÅ›li pasujÄ… do kontekstu):")
        parts.extend(ext_lines)

    if stop_lines:
        parts.append("\nğŸ›‘ STOP â€” NIE UÅ»YWAJ (przekroczone limity!):")
        parts.extend(stop_lines)

    if caution_lines:
        parts.append("\nâš ï¸ OSTROÅ»NIE â€” uÅ¼yj max 1Ã— lub pomiÅ„:")
        parts.extend(caution_lines)

    if soft_notes:
        parts.append("")
        parts.extend(soft_notes)

    return "\n".join(parts) if len(parts) > 1 else ""


def _fmt_semantic_plan(pre_batch, h2):
    plan = pre_batch.get("semantic_batch_plan") or {}
    if not plan:
        return ""

    parts = ["â•â•â• CO PISAÄ† W TEJ SEKCJI â•â•â•"]

    # H2 coverage angles
    h2_coverage = plan.get("h2_coverage") or {}
    for h2_name, info in h2_coverage.items():
        if isinstance(info, dict):
            angle = info.get("semantic_angle", "")
            must = info.get("must_phrases", [])
            if angle:
                parts.append(f'KÄ…t semantyczny: {angle}')
            if must:
                phrases = ", ".join(f'"{p}"' for p in must[:5])
                parts.append(f'ObowiÄ…zkowe frazy w tej sekcji: {phrases}')

    # Density target
    density_targets = plan.get("density_targets") or {}
    overall = density_targets.get("overall")
    if overall:
        parts.append(f'Docelowa gÄ™stoÅ›Ä‡ fraz: {overall}%')

    # Content direction
    direction = plan.get("content_direction") or plan.get("writing_direction", "")
    if direction:
        parts.append(f'Kierunek treÅ›ci: {direction}')

    return "\n".join(parts) if len(parts) > 1 else ""


def _fmt_entities(pre_batch):
    entities_for_batch = pre_batch.get("entities_for_batch") or {}
    entity_seo = pre_batch.get("entity_seo") or {}
    enhanced = pre_batch.get("enhanced") or {}
    entities_to_define = enhanced.get("entities_to_define") or []
    relations = enhanced.get("relations_to_establish") or []

    if not entities_for_batch and not entity_seo.get("enabled") and not entities_to_define:
        return ""

    parts = ["â•â•â• ENCJE (budujÄ… autorytet tematyczny) â•â•â•"]

    # Entities to INTRODUCE
    introduce = entities_for_batch.get("introduce") or []
    if introduce:
        parts.append("WPROWADÅ¹ w tym batchu (pierwsza wzmianka):")
        for ent in introduce[:5]:
            if isinstance(ent, dict):
                name = ent.get("entity", ent.get("text", ""))
                etype = ent.get("type", "")
                context = ent.get("context", "")
                line = f'  â€¢ "{name}"'
                if etype:
                    line += f" ({etype})"
                if context:
                    line += f" â€” {context}"
                parts.append(line)
            else:
                parts.append(f'  â€¢ "{ent}"')

    # Entities to DEFINE
    if entities_to_define:
        parts.append("\nZDEFINIUJ (wyjaÅ›nij czytelnikowi):")
        for ent in entities_to_define[:5]:
            if isinstance(ent, dict):
                name = ent.get("entity", ent.get("text", ""))
                hint = ent.get("definition_hint", ent.get("hint", ""))
                line = f'  â€¢ "{name}"'
                if hint:
                    line += f" â€” {hint}"
                parts.append(line)
            else:
                parts.append(f'  â€¢ "{ent}"')

    # Entities to MAINTAIN (already introduced)
    maintain = entities_for_batch.get("maintain") or []
    if maintain:
        names = ", ".join(f'"{m}"' if isinstance(m, str) else f'"{m.get("entity", "")}"' for m in maintain[:5])
        parts.append(f"\nUTRZYMUJ (juÅ¼ wprowadzone wczeÅ›niej): {names}")

    # Entity relations
    if relations:
        parts.append("\nPOWIÄ„Å» ze sobÄ…:")
        for rel in relations[:4]:
            if isinstance(rel, dict):
                subj = rel.get("subject", "")
                verb = rel.get("verb", rel.get("relation", "â†’"))
                obj = rel.get("object", "")
                parts.append(f'  â€¢ {subj} {verb} {obj}')
            elif isinstance(rel, str):
                parts.append(f'  â€¢ {rel}')

    # Must mention from entity_seo
    must_mention = entity_seo.get("must_mention") or []
    if must_mention and not introduce:
        parts.append("WSPOMNIJ w tekÅ›cie:")
        for ent in must_mention[:5]:
            if isinstance(ent, dict):
                name = ent.get("text", ent.get("entity", ""))
                parts.append(f'  â€¢ "{name}"')
            else:
                parts.append(f'  â€¢ "{ent}"')

    return "\n".join(parts) if len(parts) > 1 else ""


def _fmt_ngrams(pre_batch):
    ngrams = pre_batch.get("ngrams_for_batch") or []
    ngram_guidance = pre_batch.get("ngram_guidance") or {}

    if not ngrams and not ngram_guidance:
        return ""

    parts = ["â•â•â• POPULARNE FRAZY Z TOP10 (n-gramy) â•â•â•",
             "Te frazy czÄ™sto pojawiajÄ… siÄ™ u najlepszych wynikÃ³w. WpleÄ‡ naturalnie:"]

    for ng in ngrams[:10]:
        if isinstance(ng, dict):
            text = ng.get("ngram", ng.get("text", ""))
            count = ng.get("count", ng.get("frequency", ""))
            if text:
                parts.append(f'  â€¢ "{text}"' + (f" ({count}Ã— u konkurencji)" if count else ""))
        elif isinstance(ng, str):
            parts.append(f'  â€¢ "{ng}"')

    # Ngram guidance â€” overused, synonyms
    if ngram_guidance:
        overused = ngram_guidance.get("overused") or []
        if overused:
            over_list = ", ".join(f'"{o}"' if isinstance(o, str) else f'"{o.get("ngram", "")}"' for o in overused[:5])
            parts.append(f"\nâš ï¸ NaduÅ¼ywane n-gramy (uÅ¼yj zamiennikÃ³w): {over_list}")

        synonyms = ngram_guidance.get("suggested_synonyms") or ngram_guidance.get("synonyms") or {}
        if synonyms and isinstance(synonyms, dict):
            parts.append("Sugerowane zamienniki:")
            for orig, alts in list(synonyms.items())[:5]:
                if isinstance(alts, list):
                    parts.append(f'  â€¢ "{orig}" â†’ {", ".join(alts[:3])}')

    return "\n".join(parts) if len(parts) > 2 else ""


def _fmt_serp_enrichment(pre_batch):
    serp = pre_batch.get("serp_enrichment") or {}
    enhanced = pre_batch.get("enhanced") or {}

    paa = (serp.get("paa_for_batch") or enhanced.get("paa_from_serp") or [])
    lsi = (serp.get("lsi_keywords") or [])

    if not paa and not lsi:
        return ""

    parts = ["â•â•â• WZBOGACENIE Z SERP â•â•â•"]

    if paa:
        parts.append("Pytania ktÃ³re ludzie zadajÄ… w Google (PAA) â€” odpowiedz na 1-2 w tekÅ›cie:")
        for q in paa[:5]:
            q_text = q.get("question", q) if isinstance(q, dict) else q
            if q_text:
                parts.append(f'  â“ {q_text}')

    if lsi:
        lsi_names = [l.get("keyword", l) if isinstance(l, dict) else l for l in lsi[:8]]
        parts.append(f'\nFrazy LSI (bliskoznaczne, wpleÄ‡ naturalnie): {", ".join(lsi_names)}')

    return "\n".join(parts) if len(parts) > 1 else ""


def _fmt_continuation(pre_batch):
    continuation = pre_batch.get("continuation_v39") or {}
    enhanced = pre_batch.get("enhanced") or {}
    cont_ctx = enhanced.get("continuation_context") or {}

    # Merge both sources
    last_h2 = cont_ctx.get("last_h2") or continuation.get("last_h2", "")
    last_ending = cont_ctx.get("last_paragraph_ending") or continuation.get("last_paragraph_ending", "")
    last_topic = cont_ctx.get("last_topic") or continuation.get("last_topic", "")
    transition_hint = continuation.get("transition_hint", "")

    if not last_h2 and not last_ending:
        return ""

    parts = ["â•â•â• KONTYNUACJA â•â•â•",
             "Poprzedni batch zakoÅ„czyÅ‚ siÄ™ na:"]

    if last_h2:
        parts.append(f'  Ostatni H2: "{last_h2}"')
    if last_ending:
        ending_preview = last_ending[:150] + ("..." if len(last_ending) > 150 else "")
        parts.append(f'  Ostatnie zdanie: "{ending_preview}"')
    if last_topic:
        parts.append(f'  Temat: {last_topic}')

    parts.append("\nZacznij PÅYNNIE â€” nawiÄ…Å¼ do poprzedniego wÄ…tku, ale nie powtarzaj zakoÅ„czenia.")
    if transition_hint:
        parts.append(f'Sugerowane przejÅ›cie: {transition_hint}')

    return "\n".join(parts)


def _fmt_article_memory(article_memory):
    if not article_memory:
        return ""

    parts = ["â•â•â• PAMIÄ˜Ä† ARTYKUÅU (nie powtarzaj!) â•â•â•"]

    if isinstance(article_memory, dict):
        # Topics covered
        topics = article_memory.get("topics_covered") or article_memory.get("covered_topics") or []
        if topics:
            parts.append("Tematy juÅ¼ omÃ³wione w artykule:")
            for t in topics[:10]:
                if isinstance(t, str):
                    parts.append(f'  âœ“ {t}')
                elif isinstance(t, dict):
                    parts.append(f'  âœ“ {t.get("topic", t.get("h2", ""))}')

        # Key facts used
        facts = article_memory.get("key_facts_used") or article_memory.get("facts", [])
        if facts:
            parts.append("\nFakty juÅ¼ uÅ¼yte (nie powtarzaj):")
            for f in facts[:8]:
                parts.append(f'  â€¢ {f}' if isinstance(f, str) else f'  â€¢ {json.dumps(f, ensure_ascii=False)[:100]}')

        # Phrases used
        phrases_used = article_memory.get("phrases_used") or {}
        if phrases_used:
            high_use = [(k, v) for k, v in phrases_used.items()
                        if isinstance(v, (int, float)) and v >= 3]
            if high_use:
                parts.append("\nFrazy juÅ¼ czÄ™sto uÅ¼yte (ogranicz):")
                for name, count in high_use[:8]:
                    parts.append(f'  â€¢ "{name}" â€” juÅ¼ {count}Ã—')
    elif isinstance(article_memory, str):
        parts.append(article_memory[:1500])

    return "\n".join(parts) if len(parts) > 1 else ""


def _fmt_coverage_density(pre_batch):
    coverage = pre_batch.get("coverage") or {}
    density = pre_batch.get("density") or {}
    main_kw = pre_batch.get("main_keyword") or {}
    keyword_tracking = pre_batch.get("keyword_tracking") or {}

    if not coverage and not density and not main_kw:
        return ""

    parts = ["â•â•â• STATUS POKRYCIA FRAZ â•â•â•"]

    # Main keyword info
    if main_kw:
        kw_name = main_kw.get("keyword", "") if isinstance(main_kw, dict) else str(main_kw)
        synonyms = main_kw.get("synonyms", []) if isinstance(main_kw, dict) else []
        if kw_name:
            parts.append(f'HasÅ‚o gÅ‚Ã³wne: "{kw_name}"')
        if synonyms:
            parts.append(f'Synonimy (uÅ¼ywaj zamiennie): {", ".join(synonyms[:5])}')

    # Coverage stats
    current_cov = coverage.get("current", coverage.get("current_coverage"))
    target_cov = coverage.get("target", coverage.get("target_coverage"))
    if current_cov is not None and target_cov is not None:
        parts.append(f'\nPokrycie fraz: {current_cov}% z docelowych {target_cov}%')

    # Missing phrases â€” CRITICAL info
    missing = coverage.get("missing_phrases") or coverage.get("uncovered") or []
    if missing:
        parts.append("âš ï¸ BRAKUJÄ„CE FRAZY â€” wpleÄ‡ w tym batchu:")
        for m in missing[:8]:
            name = m.get("keyword", m) if isinstance(m, dict) else m
            parts.append(f'  â†’ "{name}"')

    # Density
    if density:
        current_d = density.get("current")
        target_range = density.get("target_range") or []
        if current_d is not None:
            range_str = f'{target_range[0]}-{target_range[1]}%' if len(target_range) >= 2 else "1.5-2.5%"
            status = "âœ… w normie" if target_range and len(target_range) >= 2 and target_range[0] <= current_d <= target_range[1] else "âš ï¸ do korekty"
            parts.append(f'\nGÄ™stoÅ›Ä‡ fraz: {current_d}% (cel: {range_str}) {status}')

        overused_d = density.get("overused") or []
        if overused_d:
            over_names = ", ".join(f'"{o}"' if isinstance(o, str) else f'"{o.get("keyword", "")}"' for o in overused_d[:5])
            parts.append(f'NaduÅ¼ywane: {over_names} â€” uÅ¼yj synonimÃ³w')

    # Keyword tracking summary
    if keyword_tracking:
        total_kw = keyword_tracking.get("total_keywords", 0)
        covered_kw = keyword_tracking.get("covered", 0)
        if total_kw and covered_kw:
            parts.append(f'\nTracking: {covered_kw}/{total_kw} fraz pokrytych')

    return "\n".join(parts) if len(parts) > 1 else ""


def _fmt_style(pre_batch):
    style = pre_batch.get("style_instructions") or pre_batch.get("style_instructions_v39") or {}

    if not style:
        return ""

    parts = ["â•â•â• STYL â•â•â•"]

    if isinstance(style, dict):
        tone = style.get("tone", "")
        if tone:
            parts.append(f'Ton: {tone}')

        para_len = style.get("paragraph_length", "")
        if para_len:
            parts.append(f'DÅ‚ugoÅ›Ä‡ akapitÃ³w: {para_len} sÅ‚Ã³w')

        forbidden = style.get("forbidden_phrases") or style.get("avoid_phrases") or []
        if forbidden:
            parts.append(f'ZAKAZANE zwroty: {", ".join(f"{f}" for f in forbidden[:8])}')

        preferred = style.get("preferred_phrases") or style.get("use_phrases") or []
        if preferred:
            parts.append(f'Preferowane zwroty: {", ".join(preferred[:5])}')

        persona = style.get("persona", "")
        if persona:
            parts.append(f'Perspektywa: {persona}')
    elif isinstance(style, str):
        parts.append(style[:500])

    return "\n".join(parts) if len(parts) > 1 else ""


def _fmt_legal_medical(pre_batch):
    legal_ctx = pre_batch.get("legal_context") or {}
    medical_ctx = pre_batch.get("medical_context") or {}

    parts = []

    if legal_ctx and legal_ctx.get("active"):
        parts.append("â•â•â• KONTEKST PRAWNY (YMYL) â•â•â•")
        parts.append("Ten artykuÅ‚ dotyczy tematyki prawnej. MUSISZ:")
        parts.append("  1. CytowaÄ‡ realne przepisy i orzeczenia (podane niÅ¼ej)")
        parts.append("  2. DodaÄ‡ disclaimer o konsultacji z prawnikiem")
        parts.append("  3. NIE wymyÅ›laÄ‡ sygnatur ani dat orzeczeÅ„")

        instruction = legal_ctx.get("legal_instruction", "")
        if instruction:
            parts.append(f'\n{instruction[:600]}')

        judgments = legal_ctx.get("top_judgments") or []
        if judgments:
            parts.append("\nOrzeczenia do zacytowania:")
            for j in judgments[:3]:
                if isinstance(j, dict):
                    sig = j.get("signature", j.get("caseNumber", ""))
                    court = j.get("court", j.get("courtName", ""))
                    date = j.get("date", j.get("judgmentDate", ""))
                    parts.append(f'  â€¢ {sig} â€” {court} ({date})')

        citation_hint = legal_ctx.get("citation_hint", "")
        if citation_hint:
            parts.append(f'\n{citation_hint}')

    if medical_ctx and medical_ctx.get("active"):
        if parts:
            parts.append("")
        parts.append("â•â•â• KONTEKST MEDYCZNY (YMYL) â•â•â•")
        parts.append("Ten artykuÅ‚ dotyczy tematyki zdrowotnej. MUSISZ:")
        parts.append("  1. CytowaÄ‡ ÅºrÃ³dÅ‚a naukowe (podane niÅ¼ej)")
        parts.append("  2. NIE wymyÅ›laÄ‡ statystyk ani nazw badaÅ„")
        parts.append("  3. DodaÄ‡ informacjÄ™ o konsultacji z lekarzem")

        instruction = medical_ctx.get("medical_instruction", "")
        if instruction:
            parts.append(f'\n{instruction[:600]}')

        publications = medical_ctx.get("top_publications") or []
        if publications:
            parts.append("\nPublikacje do zacytowania:")
            for p in publications[:5]:
                if isinstance(p, dict):
                    title = p.get("title", "")[:80]
                    authors = p.get("authors", "")[:40]
                    year = p.get("year", "")
                    pmid = p.get("pmid", "")
                    parts.append(f'  â€¢ {authors} ({year}): "{title}" PMID:{pmid}')

    return "\n".join(parts) if parts else ""


def _fmt_experience_markers(pre_batch):
    enhanced = pre_batch.get("enhanced") or {}
    markers = enhanced.get("experience_markers") or []

    if not markers:
        return ""

    parts = ["â•â•â• SYGNAÅY DOÅšWIADCZENIA (E-E-A-T) â•â•â•",
             "WpleÄ‡ min 1 sygnaÅ‚, Å¼e autor MA doÅ›wiadczenie z tematem:"]

    for m in markers[:5]:
        if isinstance(m, str):
            parts.append(f'  â€¢ {m}')
        elif isinstance(m, dict):
            parts.append(f'  â€¢ {m.get("marker", m.get("text", ""))}')

    return "\n".join(parts)


def _fmt_causal_context(pre_batch):
    enhanced = pre_batch.get("enhanced") or {}
    causal = enhanced.get("causal_context", "")
    info_gain = enhanced.get("information_gain", "")

    parts = []

    if causal:
        parts.append("â•â•â• KONTEKST PRZYCZYNOWO-SKUTKOWY â•â•â•")
        parts.append(f'{causal[:500]}')

    if info_gain:
        if parts:
            parts.append("")
        parts.append("â•â•â• INFORMATION GAIN (przewaga nad konkurencjÄ…) â•â•â•")
        parts.append(f'{info_gain[:500]}')

    return "\n".join(parts) if parts else ""


def _fmt_h2_remaining(pre_batch):
    h2_remaining = pre_batch.get("h2_remaining") or []
    if not h2_remaining:
        return ""

    h2_list = ", ".join(f'"{h}"' for h in h2_remaining[:6])
    return f"â•â•â• PLAN â•â•â•\nPozostaÅ‚e sekcje H2 w artykule: {h2_list}\nNie zachodÅº na ich tematy â€” zostanÄ… pokryte pÃ³Åºniej."


def _fmt_output_format(h2, batch_type):
    return f"""â•â•â• FORMAT ODPOWIEDZI â•â•â•
Pisz TYLKO treÅ›Ä‡ tego batcha. Zaczynaj dokÅ‚adnie od:

h2: {h2}

Potem: akapity tekstu (40-150 sÅ‚Ã³w kaÅ¼dy), opcjonalnie h3: [podsekcja].
NIE dodawaj komentarzy, wyjaÅ›nieÅ„, podsumowaÅ„ â€” TYLKO treÅ›Ä‡ artykuÅ‚u."""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FAQ PROMPT BUILDER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_faq_system_prompt(pre_batch=None):
    """System prompt for FAQ generation."""
    base = (
        "JesteÅ› doÅ›wiadczonym polskim copywriterem SEO. "
        "Piszesz sekcjÄ™ FAQ â€” zwiÄ™zÅ‚e, konkretne odpowiedzi na pytania uÅ¼ytkownikÃ³w. "
        "KaÅ¼da odpowiedÅº ma szansÄ™ trafiÄ‡ do Google Featured Snippet â€” pisz bezpoÅ›rednio i merytorycznie."
    )

    gpt_instructions = ""
    if pre_batch:
        gpt_instructions = pre_batch.get("gpt_instructions_v39", "")

    if gpt_instructions:
        return base + "\n\n" + gpt_instructions
    return base


def build_faq_user_prompt(paa_data, pre_batch=None):
    """User prompt for FAQ generation."""
    paa_questions = paa_data.get("serp_paa") or []
    unused = paa_data.get("unused_keywords") or {}
    avoid = paa_data.get("avoid_in_faq") or []
    instructions = paa_data.get("instructions", "")

    # Enhanced PAA
    enhanced_paa = []
    if pre_batch:
        enhanced = pre_batch.get("enhanced") or {}
        enhanced_paa = enhanced.get("paa_from_serp") or []

    # Stop keywords
    keyword_limits = {}
    if pre_batch:
        keyword_limits = pre_batch.get("keyword_limits") or {}
    stop_raw = keyword_limits.get("stop_keywords") or []
    stop_names = [s.get("keyword", s) if isinstance(s, dict) else s for s in stop_raw]

    # Style
    style = {}
    if pre_batch:
        style = pre_batch.get("style_instructions") or {}

    # â”€â”€ Build prompt â”€â”€
    sections = []

    sections.append("""â•â•â• SEKCJA FAQ â•â•â•
Napisz sekcjÄ™ FAQ. Zaczynaj DOKÅADNIE od:
h2: NajczÄ™Å›ciej zadawane pytania""")

    # PAA questions
    all_paa = list(dict.fromkeys(paa_questions + enhanced_paa))  # deduplicate
    if all_paa:
        sections.append("Pytania z Google (People Also Ask) â€” to NAPRAWDÄ˜ pytajÄ… uÅ¼ytkownicy:")
        for i, q in enumerate(all_paa[:8], 1):
            q_text = q.get("question", q) if isinstance(q, dict) else q
            if q_text and q_text.strip():
                sections.append(f'  {i}. {q_text}')
        sections.append("Wybierz 4-6 najlepszych. MoÅ¼esz przeformuÅ‚owaÄ‡, ale zachowaj sens.")

    # Unused keywords
    if unused:
        if isinstance(unused, dict):
            unused_list = []
            for cat, items in unused.items():
                if isinstance(items, list):
                    unused_list.extend(items[:5])
                elif isinstance(items, str):
                    unused_list.append(items)
            if unused_list:
                names = ", ".join(f'"{u}"' if isinstance(u, str) else f'"{u.get("keyword", "")}"' for u in unused_list[:8])
                sections.append(f'\nFrazy jeszcze nieuÅ¼yte â€” wpleÄ‡ w odpowiedzi: {names}')
        elif isinstance(unused, list):
            names = ", ".join(f'"{u}"' for u in unused[:8])
            sections.append(f'\nFrazy jeszcze nieuÅ¼yte â€” wpleÄ‡ w odpowiedzi: {names}')

    # Avoid topics
    if avoid:
        topics = ", ".join(f'"{a}"' if isinstance(a, str) else f'"{a.get("topic", "")}"' for a in avoid[:8])
        sections.append(f'\nNIE powtarzaj tematÃ³w juÅ¼ pokrytych w artykule: {topics}')

    # Stop keywords
    if stop_names:
        sections.append(f'\nğŸ›‘ STOP â€” NIE UÅ»YWAJ: {", ".join(f"{s}" for s in stop_names[:5])}')

    # Style
    if style:
        forbidden = style.get("forbidden_phrases") or []
        if forbidden:
            sections.append(f'ZAKAZANE zwroty: {", ".join(forbidden[:5])}')

    # Article memory
    if pre_batch and pre_batch.get("article_memory"):
        mem = pre_batch["article_memory"]
        if isinstance(mem, dict):
            topics = mem.get("topics_covered") or []
            if topics:
                topic_names = [t if isinstance(t, str) else t.get("topic", "") for t in topics[:6]]
                sections.append(f'\nTematy z artykuÅ‚u (nie powtarzaj): {", ".join(topic_names)}')

    # Instructions from API
    if instructions:
        sections.append(f'\n{instructions}')

    # Format
    sections.append("""
â•â•â• FORMAT â•â•â•
h2: NajczÄ™Å›ciej zadawane pytania

h3: [Pytanie â€” 5-10 sÅ‚Ã³w, zaczynaj od Jak/Czy/Co/Dlaczego/Ile]
[OdpowiedÅº 60-120 sÅ‚Ã³w]
â†’ Zdanie 1: BEZPOÅšREDNIA odpowiedÅº
â†’ Zdanie 2-3: rozwiniÄ™cie z konkretem
â†’ Zdanie 4: praktyczna wskazÃ³wka lub wyjÄ…tek

Napisz 4-6 pytaÅ„. Pisz TYLKO treÅ›Ä‡, bez komentarzy.""")

    return "\n\n".join(sections)
